{"posts":[{"title":"33rd Degree 2014","text":"This year 33rd Degree conference is over. I’m glad I could help Grzesiek in the organization as a volunteer. It was a good experience and great opportunity to meet new people. For me the biggest advantage of this conference are talks. There were many rock star speakers with cutting edge topics. I would like especialy say thank you to Tomek Nurkiewicz. His talk was about Saiku. Tomek charisma, teaching skills, good preparation and selection of material is at the highest possible level. Thus that, after one hour I felt like an expert of Saiku and OLAP. Thank you and see you next year. Photo credit","link":"/2014/06/33rd-degree-2014/"},{"title":"Unlocking Team Potential - The 7 Levels of Initiative","text":"In our world of engineering management, a big question arises: “What is the best reward for an Engineering Manager?” People have many different answers to this. For me, the best reward is seeing my team grow and do well on their own. Think about a day at work when your team is full of energy and ideas. They solve problems quickly and work well together. And you? You’re helping them succeed and focusing on the big picture. Your job isn’t just about managing; it’s about leading in a new way. So, how do we make this happen? How do we unite a group to form a strong team that does better than we ever hoped? The answer is in encouraging initiative. In this blog post, I’ll discuss the 7 Levels of Initiative, an idea from Steven Covey’s research. It’s not just a way to check how well the manager is doing in the team; it’s about helping our teams be their best. Theory about initiative Understanding Initiative in Engineering TeamsThe initiative is about taking action before being asked. It’s seeing a problem or opportunity and addressing it right away. In engineering, having initiative means being ahead of the game - thinking ahead, solving problems quickly, and constantly looking for ways to improve. It shows a team member is engaged, responsible, and ready to contribute creatively. In short, initiative is key for a team to innovate, adapt, and excel. Everyday Initiative Beyond Big ChangesA common notion I often encounter is the belief that initiative is limited to the architecture changes or big team process changes and that this done, so there is no place to put more initiative. However, I believe the initiative starts and manifest in everyday situations, even within established frameworks of team work. The initiative isn’t just about making large-scale changes or redesigning project architectures. It’s often about the smaller, impactful actions that enhance team performance and project outcomes. For instance, a team member might proactively arrange an immediate meeting to tackle a recurring issue, showing a keen sense of urgency and problem-solving instead of waiting for a scheduled retrospective meeting for the next week. Another example is a team member taking the lead on an small training session to share knowledge about a new tool. Spotting Low InitiativeIn a large team (or teams) setting, it’s vital to identify signs of low initiative among team members. Phrases like “That’s not my role,” “No one told me I should do this,” or “I have never done this before” are typical indicators. These statements suggest a reluctance to step out of a defined role or comfort zone, waiting for explicit directions rather than seeking opportunities to contribute. This mindset can slow the team’s progress, especially in larger groups where individual initiative drives efficiency and innovation. Recognizing and addressing these signs through coaching or creating opportunities for members to take on new challenges is essential for nurturing a proactive and dynamic team environment. 7 levels of initiativeStephen R. Covey’s classification of initiative comprises 7 distinct levels, each representing a different degree of decision-making autonomy. It’s crucial to recognize the shift in decision-making power between levels 1-4 and 5-7, with the latter starting with a ‘do it’ approach. In Levels 1-4, there’s constant communication, with the shift being in who initiates action: you or your direct report. Levels 5-7 represent a transition to less control, requiring significant trust in your reports. These levels lack a ‘final check’ by the manager, tech lead, or team, and employees need significant courage to take action and handle the potential risks. 1. Wait Until ToldHere, team members are entirely reactive, depending on direct instructions. Typical of new hires or in structured environments, this level shows no proactivity. Such individuals don’t seek what to do next or show curiosity, solely waiting for external input. 2. AskAt this level, team members start to show interest by seeking tasks, indicating a move toward greater engagement. Questions like “What can I do next?” or “Why are we working this way?” arise, directed at you, the team, or themselves. 3. Make recommendationsA significant shift occurs here. Engineers not only ask questions but also provide answers, leading to idea generation. The key is their ability to propose concrete changes to the status quo, offering multiple potential solutions to a problem. 4. “I intend to do”Adding to the previous level, an engineer with multiple solutions for a problem can choose one, devise an action plan, and inform others of their intent. The plan may vary in scope, from a few days of changes to significant team process adjustments or large refactorings in the code base or larger architecture changes. 5. Do it and report immediatelyAutonomy increases as team members act independently and report back immediately. This level reflects trust and a solid grasp of responsibilities. It’s evident when someone updates you with results and conclusions from their independent work. 6. Do it and report periodicallyTeam members at this level take complete ownership of tasks, making decisions independently. They align closely with the team’s vision, requiring minimal oversight. Periodic updates are agreed upon to monitor progress. 7. Do itThe pinnacle of initiative, where engineers act independently and only communicate the completion of their tasks or changes, bypassing progress updates to managers or tech leads. Refining 7 levels of initiativeThe Role of Initiative Levels in DelegationUnderstanding the levels of initiative is crucial in delegating tasks effectively. When I assign a task, I also relate to the initiative level which helps set clear expectations. Early in my role as an engineering manager, I learned this the hard way. My delegation approach was vague, leading to varied outcomes based on the initiative levels of my team members. For instance, asking someone to work on “feature X” without specifying the expected level of initiative could result in a barrage of questions (level 2), a list of proposed solutions (level 4), or even a completed feature (level 7).This experience taught me the importance of clear communication and setting precise expectations about the desired level of initiative for each task. Characteristics at Higher Levels of InitiativeWhen dealing with higher levels of initiative, several factors become increasingly important: Trust between the manager and the engineer needs to be higher. The engineer’s competence and skill level should be higher (not only technical but also leadership as the delegated task is rarely work-alone task). There should be a noticeable willingness and eagerness to engage with the task. Especially the willingness to take calculated risks becomes more pronounced. Creativity in approaching and solving problems is essential. Embracing Ownership and AccountabilityAt higher levels, accountability plays a significant role. Often, people may shy away from accountability, possibly due to fear of failure or lack of confidence. However, true ownership of a task requires being accountable and making decisions. Being accountable means not just delivering what is agreed upon but also proactively seeking ways to enhance the product and improve processes. A proactive approach and higher levels of initiative are fundamental to this ownership. Navigating Between Levels in 1-on-1sIn my 1-on-1 meetings, I aim to challenge my team members to ascend to higher levels of initiative - of course, tailored to each individual’s capabilities. However, it’s important to recognize when someone might be pushed too quickly to a higher level. For instance, if we agree on level 6 but the engineer struggles and makes mistakes, it’s crucial to be able to step back to a lower level of initiative. This adjustment should be clearly communicated, specifying the duration and method of this change. Such flexibility and guidance are key to effectively nurturing and developing each team member’s potential. Three Strategies to increase the initiativeTo boost initiative within a team, focus on these three strategies: Setting clear expectations. Empowering decision-making Rewarding initiative. Clear ExpectationsIt’s essential to communicate that initiative and proactive behavior are important. Clearly define these behaviors and how they align with the team’s goals and the overall project vision. Misunderstandings often arise when managers expect initiative but don’t clarify what constitutes ‘good performance’ or ‘desirable behavior.’ In my experience, discussing the ‘7 Levels of Initiative’ with team members clarifies these expectations. This is something I do with my teams. Engineers need to understand that their performance is evaluated not just based on task completion, like delivering features or fixing bugs, but also on their attitude and behavior. Empowering Decision-MakingEnhancing initiative in your team means empowering them at various levels. Start by assigning meaningful tasks challenging and developing their skills, signaling trust and encouraging ownership. Foster an environment that values autonomy, allowing team members to make decisions and bring their ideas to fruition. Open communication channels encourage sharing ideas and feedback, and embracing calculated risk-taking, with failures seen as opportunities for learning, is crucial. I’ve shared this model and discussed this with my team. That’s why when we talk, it is easier to discuss daily topics. Understanding individual motivators and ensuring alignment with team goals is important. Recognize that not everyone will jump from lower to higher initiative levels instantly; gradual progression is key, along with providing room for mistakes and learning. Recognizing and Rewarding InitiativeAcknowledging and rewarding initiative is more effective than providing constructive feedback.Consider my personal story: It was a warm and sunny day. My son (4 years old) was eager to wash our new car, as he was excited about it. We started with preparations. I asked him to prepare water with car shampoo as he enjoys playing with water (aligning the task to the motivators). Unfortunately, he used the entire bottle of shampoo instead of a few drops. Rather than penalizing him, which could discourage future help, guidance is more effective. Truth to be told. A bottle of car shampoo is not expensive. He was so passionate about cleaning the car itself that he needed a strong reward for the whole work. Similarly, positive feedback and rewards foster a culture of initiative in a professional setting. Rewards can be financial, like bonuses, but often more impactful are Personal acknowledgment in 1-on-1s Faster promotion to a higher level Public praise Granting more autonomy Assigning more significant, impactful projects Providing opportunities to tackle more interesting and challenging tasks Manager perspectiveInitiative in Performance ReviewsIn the context of performance reviews, understanding initiative goes beyond just completing a task well. As a manager, I place significant emphasis not only on the outcome of the task but also on the level of engagement and involvement demonstrated by the team members in accomplishing it. The initiative is reflected in how an individual approaches a task - their ability to think proactively, anticipate potential challenges, and engage with the task creatively and enthusiastically. It’s about showing eagerness to take on responsibilities, to contribute ideas, and to go the extra mile. When reviewing performance, I look for signs of this deeper engagement: Has the team member shown a willingness to learn and adapt? Have they taken steps to improve processes or collaborate effectively with others? The important aspect is that this relates to the task, not the engineer. Each engineer is assigned to many tasks; the initiative level is correlated with the task, not with the particular engineer. In essence, initiative in performance is about the attitude and approach towards work, not just the technical execution of tasks. It’s this comprehensive view of performance that truly reflects a team member’s contribution and growth potential. Addressing Lack of Initiative in Behavioral InterviewsWhen evaluating candidates, I’ve encountered at least two times engineers who excel in coding and system design, yet exhibit a noticeable need for more initiative in their behavior, thus having to be rejected. This presents a unique challenge, especially in roles where proactive engagement and the ability to drive projects independently are crucial (especially senior roles). During the behavioral interview, it becomes apparent that while they possess strong technical skills, their approach to problem-solving and project management might be more reactive than proactive. This gap is significant because, in dynamic work environments, the ability to anticipate challenges, propose solutions, and take charge of situations is as valuable as technical proficiency. Addressing this during the interview involves probing deeper into their past experiences and scenarios where they might have taken the initiative. It’s also about evaluating their potential to develop this skill, considering the team’s current dynamics and the support structure available to nurture such growth. SummaryIn this post, we explored what makes a great engineering manager: seeing your team work well on their own. We talked about the 7 Levels of Initiative from Steven Covey’s ideas, showing how important it is for team members to take action on their own, from big project changes to small daily tasks. We learned that it’s key to be clear when you give tasks to your team, so they know what you expect from them in terms of taking charge. Higher levels of initiative need trust, skill, willingness, and creativity. It’s also about being okay with taking risks and being responsible for your work. When looking at how well team members are doing, it’s not just about finishing tasks. It’s also about how they approach their work and if they’re willing to try new things. For bigger teams, it’s important for each person to manage their own work because the manager can’t guide everyone all the time. Lastly, we saw that in job interviews, it’s important to find people who can think ahead and solve problems on their own, not just those who are good at coding. In short, for a team to be successful, everyone needs to be able to think for themselves and be willing to take on new challenges. This helps the team work better and makes the job of an engineering manager rewarding.","link":"/2024/01/7-levels-of-initives/"},{"title":"Sam Newman - Building Microservices","text":"Two days after the ending of GeeCON, I’ve managed to read „Building Microservices” by Sam Newman Book. It is in Early Release stage, so half of the chapters were missing. The first chapter about concept of microservices is very good. It determines the direction of thinking. It relates to SOA, OSGI, and many know to me aspects and problems. If you do not know what microservices are, read only this chappter. The rest completed chapters were good. I had a feeling that those chapters were written not only for architects, but for developers in the first place. There were funny sentences like „Big Scary CRM”. I was also enjoyed because there were many real life system described. To summarize. I am looking forward for the finished book, to read it again. Also I would like to try to implements some solutions in microservices way :) Photo credit","link":"/2014/05/Newman-Microservices/"},{"title":"First thoughts about Rust","text":"IntroductionI wanted to try new programming language. A language that is trivial and complex at the same time. Trivial to write fast, complex when struggling with performance or when you want state of art architecture. Baby stepsThis week I decided to try Rust . Rust is an expression-based language. What this mean? In general expression is collection of symbols that jointly express a quantity (or simply expression produce at least one value). But there are also statements which may be smallest standalone elements of an programming language or in other words statements are building blocks of the program.In Rust everything is an expression, but in general we have two kind of statements. First is an binding statement (for example statement declaration) and second is expression statement, which purpose is to turn any expression into statement (for example adding ; at the end of the line). Why I even write this? Look at this if example which is statement. If expression1let y = if x == 5 { 10 } else { 15 }; // y: i32 Notice that there are no semicolons after 10 and 15. This means that those are expression, and ‘if’ is an expression to, which mean that you can assign if result to y. The basic programAfter reading the first part of the Rust Book I decided to write my first program. I decided to write quick sort. Here is the code.Lessons learned: Writing a program without IDE and relay only on docs and error codes its very valuable for your learning progress. Cargo, which is Rust build system is intuitive. Out of the box test and benchmark support is another advantage. Primitives like in C. Good when struggling with performance. Bad when want to write fast. Pointers like in C. Dangerous, but powerful toy. In next section there is a few words about how Rust extended pointer that I knew from C. I didn’t like the ‘newtype’, that let you create a new type that’s similar to another one. The concept is good, but after this example, I would say I won’t use it (in most of the cases), because cost of difficulty in extracting value, is not worth providing this kind of type safe: 123let length = Inches(3); let Inches(integer_length) = length; println!(&quot;In inches size {}&quot;, length); I didn’t like that Rust has two main types of strings: &amp;str and String. Memory managementRust is about performance. Many of abstractions are done at compile time. There is said that new programers are fighting with compiler. I can confirm that. Once you gain more experience, it is all becoming easy for you. I have to admit that I’ve similar situation with Scala. Experience of learning my first programming language came to me when in book pass-reference-by-value was discussed.Rust take pointers to the whole new level. There are mutable references, boxes and more.But in fact pointers are an introduction to Rust memory aspect such as: Ownership, Borrowing, Boxes and Lifetimes. I’ve great time playing around and checking what will work and what not. This is a recommended part of the book and this article for further reading. For me it was good learning journey to read and try new Language. What will be next? Maybe Go or Haskell. Photo credit: Rust Car, Rust Nut","link":"/2015/03/Rust/"},{"title":"Scalania","text":"On July 10, there was an event called “Scalania“. A group of Scala developers and Scala “wannabe” developers, meet at Warsaw University Of Technology. We were solving 99-scala problems. Result of our work can be found at bitbucket. Photo credit","link":"/2013/07/Scalania/"},{"title":"Agile By Example 2013","text":"Agile By Example is over. It was good three days. Organizers do they’s best. There was great organization, good internet acces and good food. Jeff Suterland keynote was average. For me the real keynote was given by Sandro Moncuso “Software craftsmanship”. In the second day, good speach gave Jurgen Appelo and Tom Gilb. Tom Gilb presentation was challenging. Slides were awful. Tom marked many times that we must deliver value. Remember that value may be delivered without single line of code. One of the tools that Tim presented was “Value Decision Tables” which may look as sophisticated Excel system. But Krzysztof Jelski, on the next day presented “Impact Mapping” tool which was very easy to use. I’ve meet Agile from a new perspective. It was good for me that I’ve joined this conference. Thank you SoftwareMill and Touk for this event. Photo credit","link":"/2013/10/agile-by-example-2013/"},{"title":"Agile IT Organization Design","text":"General impressionsAgile promises to deliver solutions through collaborative effort, cross functional team design, modern programming methods and probably many more things. Because of that, it is hard to distinguish between part and parcel of Agile, and optional techniques that were developed over time. Agile IT Organization Design by Sriram Narayan is a bird’s eye view on Agile topics and tries to organize them. As the author mentions multiple things that are somehow related to Agile, starting with project estimations, through project finance and software development practices, ending with team room layout, the reader should be ready to jump over the wide variety of topics. Putting so many subjects in one book causes that specific aspects are discussed from time to time without any case-studies or detailed guidance how to kick start those ideas. It is valuable if you want to get a general idea, but mediocre if you want to get in-depth knowledge. There is nothing to worry about, because there are a lot of references to other publications or books, which may help you to explore more. The good thing is that at the end of each chapter there is a summary, which after short skimming, helped me to create my own book reading order. Author very often, explain reasons for doing things in a certain fashion. This approach helped me to reflect what and how I did in the past, and hopefully, it will help me make better decisions in the future. RecommendationsThis book is written for people from all walks of life. You can read it if you are a leader, a product owner, a software engineer or a stakeholder. It would be favourable if every person read that book, but it is not possible. If you work in a modern organization and you have the general understanding of bolts and nuts of Agile processes, you will probably not lose much by skipping that book. It is a good book for someone who would like to take a break from technical books and read something without code listings inside. Also, I would recommend this book to reach out for a particular chapter which are in the area of your interest. Key takeawaysI have highlighted over 50 sentences in this book. Some of them to remember, other to think about or to discuss them with colleagues. I have selected 9 that stuck in my mind: End-to-end cycle time is more important than team development velocity. Doing sprints doesn’t make it iterative development. An engineering team without a clear leader may have trouble settling down on a solution design. The product is never mature; it is always maturing until it is finally obsolete. Move from a project centric model of execution to a product-centric model. Labeling people with job titles like an engineer, a manager, a QA, may have side effects. Spoken language influences the way we think. People say tl;dr to anything longer than a tweet.","link":"/2019/01/agile-it-organization-design/"},{"title":"Powiadomienia wprost z Google Chrome","text":"Moim skromnym zdaniem Gmail jest najlepszy. Koniec kropka.Teraz dochodzą powiadomienia wprost z Gmaila :)Najpierw przypinamy sobie kartę z Gmail-em: Następnie ustawienia Gmaila ( zakładka General) i cieszymy się nowymi powiadomieniami: Możemy teraz przetestować nowy system notyfikacji: Działa na Chrome na OS X i Linuxie. Photo credit","link":"/2011/01/chrome-notifications/"},{"title":"Two best books in 2019","text":"According to The National Library of Poland research, only 10% of Poles read at least 7 books per year. I know that we are not reading a lot, and it was no surprise for me. Conversely, this fact motivated me to investigate to do some health-check about my reading. The challengeAt the beginning of 2019, I thought that I read approximately about 10 books a year, but I wasn’t sure. My regular peace is one book a month, but I didn’t measure it in any way. I’ve decided to change it. Goodreads reading challenge was a game-changer for me. This technique meets the SMART goal requirement. It was specific, measurable and since I know that I read about 10 books a year, I could set a target that was also achievable. I’ve decided to commit to reading 15 books in the year 2019. In fact, I’ve managed to read 18 books. From all of those 18 read books, I’ve selected two books that have the biggest impact on my career as a Technical Leader. Best technical bookDesigning Data‑Intensive Applications by Martin Kleppmann is a must-read for every Software Engineer. If you think that you are not building (or will never build) a distributed system, look at Single-Threaded CPU Performance, for the last ten years. The CPU performance is not increasing so rapidly that it used to. That’s why we should learn how to build complex and distributed systems, using only commodity class machines. Before I start discussing this book, we need to distinguish between two terms: competence and knowledge.Competence is about ability, a certain area of skills that allows you to perform well. Knowledge is just only knowing things. In most cases, you can Google for facts you are looking for. Take a look at the following answer at Quora. Access to StackOverflow is Knowledge. Knowing which code to copy from StackOverflow is Competence. This book helps you gain Competence. Let’s discuss the book itself. To align the level of the reader’s understanding of a more advanced topic, this book introduces fundamental databases or data related algorithms. You may be surprised how many Software Engineers do not know these things. The most precious thing that you get from this book is a big picture view of how many databases and data processing frameworks work under the hood. Also, you will learn by example how to create distributed systems. What is more, the author is not focusing only on a single technology or database. He constantly contrasting and comparing different solutions, both used today and that we were using some time ago. If you would want to only read databases documentation to gain this knowledge, you would have to spend far more time reading and analyzing it, that reading that book. Best leadership bookWhat Got You Here Won’t Get You There by Marshall Goldsmith is a good lecture if you work a lot with other people, and obligatory lecture if you want to be a leader or manager. What you need to know about the author is that he was a coach for many CEOs in multiple companies. That is an impressive achievement and I thought that this book may be valuable. Furthermore, my friend recommended it to me, so it was a must-read for me. What is unusual about this book is that the author focuses on one and only one aspect of leadership: Changing Your behavior. Dr. Marshall, in the first part of his book, explained 20 common behavioral mistakes, that not only many people do, but most importantly many managers or directors commit. I constantly asked myself: “What I would do If I were in that situation”. Realizing that I’m not perfect, was an important discovery for me, which forced me to change. The second part of this book, helps you discover your weaknesses and support you to change your behavior. It presents many techniques, most of which may be implemented right away. On the other hand, this book is sometimes boring. It spends too much talking about the same issue or repeating itself. It could be more condensed. FeedbackCurrently, I preparing my reading list for 2020. It will be only 12 books, but I want to select the best books that I can read. That is why I would welcome any suggestions from you. If you are a Software Engineer, I would like to know your reading habits. Do you read more or less? What do you read? Can you recommend something? Leave a comment :) Photo credit","link":"/2020/01/best-books-in-2019/"},{"title":"Clojure - How to replace current time creation?","text":"Recently, I’ve begun my adventure with Clojure programming language. As a result I’ve decided to share gathered knowledge and my opinion, in this and in few upcoming posts. The problemI had to implement algorithm that depends on the current date. Core information for this algorithm is number of days between current date and some date in the future, expressed in days.Therefore, there is a call somewhere in the code: Current time with Java 81(. java.time.LocalDate now) For the tests to be stable, I had to make sure that this call always return the same day. Approach 1I’ve decided to extract creation of the current date functionality to the function: now-date function will return current time1(defn now-date [] (. java.time.LocalDate now)) During tests I’ve declared different function: fixed-date function will return current time1(defn fixed-date [] (. java.time.LocalDate of 2015 01 28)) Passing function that creates a current date, solved the problem. It worked great, but it had the following disadvantages: Passing to algorithm function that creates current time. Using java notation (with dot) in Clojure. Approach 2Having a function, that returns a current time, I’ve decided to find a way of overwriting its definition in tests. I’ve found out that there is operation called with-redefs-fn, which allows re-defining the function temporarily in the local context. Having defined fixed-date function, block of code looks like this: Replacing now-date with fixed-date123456789(deftest my-test (with-redefs-fn { #'fixture/now-date fixed-date } #(do (testing &quot;should work method a&quot; (let [result (fixture/do-stuff 30)] (is (.equals 8.22M result)) )) ;More tests ))) fixture/now-date is a reference to function that I wanted to replace. This time I was amazed by language possibilities. But there was one more problem to solve. I did not want to use java notation. Approach 3There is a library called Clj-time. It wraps Joda Time library and makes Clojure code more friendly. I wanted to hold on Java 8 library, but I did not see any alternatives. So I replaced (. java.time.LocalDate now) to (t/now) and also creation of fixed dates, and then I came up with an idea. Approach 4Maybe should I replace the Clj-time itself? My production code will be simpler and the test code will be simpler too! Replacing t/now with fixed date123456789(deftest my-test (with-redefs-fn { #'t/now #(t/date-time 2015 11 19) } #(do (testing &quot;should work method a&quot; (let [result (fixture/do-stuff 30 1000)] (is (.equals 8.22M result)) )) ;More tests ))) This is my final solution. I am still impressed how easily it that can be done. I use Clojure for a week. If you have any other ideas how to solve this problem comment, let me know. Photo credit: Vintage alarm clock, Thumbnail","link":"/2015/11/clojure-time/"},{"title":"Clojure - Fascinated, Disappointed, Astonished","text":"I’ve had a pleasure to work with Piotrek Jagielski for about two weeks on Clojure project. I’ve learned a lot, but there is still a lot to know about Clojure for me. In this post I’ll write what fascinated, disappointed and astonished me about this programming language. Clojure &amp; InteliJ IDEA tipsBefore you start your journey with Clojure: Use Cursive plugin for InteliJ IDEA. In ‘14 Edition it was not in the standard plug-in repository (remove La Clojure plug-in and Cursive repository manually). For IDEA ‘15 it is in repository. Colored brackets help me a lot. You can find configuration for colored brackets on Misophistful Github. FascinatedSyntaxFor many people Clojure brackets are reasons to laugh. Jokes like that were funny at first: “How many brackets did you write today?”I have to admit, that at the beginning using brackets was not easy for me. Once I’ve realized that the brackets are just on the other side of the function name, everything was simple and I could code very fast.After few days I’ve realized that this brackets structure forces me to think more about the structure of the code. As a result the code is refactored and divided into small functions.Clojure forces you to use good programming habits. Data structure is your codeClojure is homoiconic, which means that the Clojure programs are represented by Clojure data structures. This means that when you are reading a Clojure code you see lists, maps, vectors. How cool is that! You only have to know few things and you can code. Do not restart your JVMBecause Clojure code is represented as data structures, you can pass data structure (program) to running JVM. Furthermore, compiling your code to bytecode (classes, jars) may be eliminated. For example, when you want to test something you are not obligated to start new JVM with tests. Instead you can just synchronize your working file with running REPL and run the function. Traditional way of working with JVM is obsolete. In the picture above, on the left you can see an editor, on the right there is running REPL. The same way you can run tests, which is extremely fast. In our project we had ~80 tests. Executing them all took about one second. Easy to readSimplicity is the ultimate sophistication. Leonardo da Vinci After getting familiar with this language, it was really easy to read code. Of course, I was not aware of everything what was happening under the hood, but consistency of the written program evoked sense of control. DisapointedData structure is your codeWhen data structure is your code, you need to have some additional operators to write effective programs. You should get to know operators like ‘-&gt;&gt;’, ‘-&gt;’, ‘let’, ‘letfn’, ‘do’, ‘if’, ‘recur’ … Even if there is a good documentation (e.g. Let), you have to spend some time on analyzing it, and trying out examples. As the time goes on, new operators will be developed. But it may lead to multiple Clojure dialects. I can imagine teams (in the same company) using different sets of operators, dealing with the same problems in different ways. It is not good to have too many tools. Nevertheless, this is just my suspicion. Know what you doI’ve written a function that rounds numbers. Despite the fact that this function was simple, I wanted to write test, because I was not sure if I had used the API in correct way. There is the test function below: Rounding test12(let [result (fixture/round 8.211M)] (is (= 8.21M result)))) Unfortunately, tests were not passing. This is the only message that I received: Rounding test1234:error-while-loading pl.package.calc-testNullPointerException [trace missing](pst)NullPointerException Great. There is nothing better than a good exception error. I’ve spent a lot of time trying to solve this, and solution was extremely simple.My function was defined with defn-, instead of defn. defn- means private scope and test code, could not access testing function. Do not trust assertionsAssertions can be misleading. When tested code does not work properly and returns wrong results, error messages are like this: Assertions problems1234ERROR in math-test/math-operation-test (RT.java:528)should round using half upexpected: (= 8.31M result) actual: java.lang.IllegalArgumentException: Don't know how to create ISeq from: java.math.BigDecimal I hadn’t got time to investigate it, but in my opinion it should work out of the box. SummaryIt is a matter of time, when tools will be better. Those problems will slow you down, and they are not nice to work with. AstonishedThe Clojure concurrency impressed me. Until then, I knew only standard Java synchronization model and Scala actors model. I’ve never though that concurrency problems can be solved in a different way. I will explain Clojure approach to concurrency, in details. Normal variablesThe closest Clojure’s analogy to the variables are vars, which can be created by def. Vars1234(defn a01 [] (def amount 10) (def amount 100) (println amount)) We also have local variables which are only in let scope. If we re-define scope value of amount, the change will take place only in local context. Lets12345(defn a02 [] (let [amount 10] (let [amount 100] (println amount)) (println amount))) The following will print: Lets output1210010 Nothing unusual. We might expect this behavior. Concurrent access variablesThe whole idea of concurrent access variables can be written in one sentence. Refs ensures safe shared access to variables via STM, where mutation can only occur via transaction.Let me explain it step by step. What is Refs?Refs (reference) is a special type to hold references to your objects. As you can expect, basic things you can do with it is storing and reading values. What is STM?STM stands for Software Transactional Memory. STM is an alternative to lock-based synchronization system. If you like theory, please continue with Wikipedia, otherwise continue reading to see examples. Using RefsRefs reads123(defn a03 [] (def amount (ref 10)) (println @amount)) In the second line, we are creating reference. Name of this reference is amount. Current value is 10.In the third line, we are reading value of the reference called amount. Printed result is 10. Modifying Refs without transactionRefs writes without transaction1234(defn a04 [] (def amount (ref 10)) (ref-set amount 100) (println @amount)) Using ref-set command, we modify the value of the reference amount to the value 100. But it won’t work. Instead of that we caught exception: Exception1IllegalStateException No transaction running clojure.lang.LockingTransaction.getEx (LockingTransaction.java:208) Using transactionRefs writes with transaction1234(defn a05 [] (def amount (ref 10)) (dosync (ref-set amount 100)) (println @amount)) To modify the code we have to use dosync operation. By using it, we create transaction and only then the referenced value will be changed. Complete exampleThe aim of the previous examples was to get familiar with the new operators and basic behavior.Below, I’ve prepared an example to illustrate bolts and nuts of STM, transactions and rollbacks. The problemImagine we have two references for holding data: source-vector containing three elements: “A”, “B” and “C”. empty destination-vector. Our goal is to copy the whole source vector to destination vector. Unfortunately, we can only use function which can copy elements one by one - copy-vector. Moreover, we have three threads that will do the copy. Threads are started by the future function. Keep in mind that this is probably not the best way to copy vectors, but it illustrates how STM works. Refs writes with transaction123456789101112131415161718192021(defn copy-vector [source destination] (dosync (let [head (take 1 @source) tail (drop 1 @source) conj (concat head @destination)] (do (println &quot;Trying to write destination ... &quot;) (ref-set destination conj) (println &quot;Trying to write source ... &quot;) (ref-set source tail) (println &quot;Sucessful write &quot; @destination)))))(defn a06 [] (let [source-vector (ref [&quot;A&quot; &quot;B&quot; &quot;C&quot;]) destination-vector (ref [])] (do (future (copy-vector source-vector destination-vector)) (future (copy-vector source-vector destination-vector)) (future (copy-vector source-vector destination-vector)) (Thread/sleep 500) @destination-vector ))) ExecutionBelow is the output of this function. We can clearly see that the result is correct. Destination vector has three elements. Between Sucessful write messages we can see that there are a lot of messages starting with Trying to write.What does it mean? The rollback and retry occurred. Printed messageslang:Clojure1234567891011121314(l/a06)Trying to write destination ...Trying to write source ... Trying to write destination ...Trying to write destination ... Sucessful write (A)Trying to write destination ...Trying to write destination ...Trying to write source ...Sucessful write (B A)Trying to write destination ...Trying to write source ...Sucessful write (C B A)=&gt; (&quot;C&quot; &quot;B&quot; &quot;A&quot;) RollbackEach thread started to copy this vector, but only one succeed. The remaining two threads had to rollback work and try again one more time. When Thread A (red one) wants to write variable, it notices that the value has been changed by someone else - conflict occurs. As a result, it stops the current work and tries again whole section of dosync. It will try until every write operation succeed. Pros and cons of STMCons: Everything that happens in dosync section has to be pure, without side effects. For example you can not send email to someone, because you might send 10 emails instead of one. From performance perspective, it makes sense when you are reading a lot from Refs, but rarely writing it. Pros: Written code is easy to read, understand, modify. Refs and transactions are part of standard library, so you can use it in Vanilla Java. Take a look at this blog post for more examples. SummaryThere is a lot that Java developers can gain from Clojure. They can learn how to approach the code and how to express the problem in the code. Also they can discover tools like STM. If you like to develop your skills, you should definitely experiment with Clojure.","link":"/2016/01/clojure-summary/"},{"title":"The Engineering Manager&#39;s 10-Step Blueprint for Effective Written Communication","text":"Effective communication is pivotal in engineering management. This blog aims to dissect the intricacies of written communication, offering insights and practical tools to enhance your interactions. While I’m no Shakespeare, writing gives me a sense of clarity. It’s a medium where I can truly articulate my thoughts and share knowledge. But let’s face it, written communication has its challenges—no facial expressions, no tone, just words on a screen. Understanding this gap is crucial for effective communication. This blog post aims to dig into the complexities of written communication, offering you a detailed roadmap for improvement. Whether you’re drafting an extensive project plan or shooting off a quick Slack message to your team, the principles outlined in this blog can elevate your written communication across all platforms.” Why written communication is challenging? In verbal communication, tone, pitch, and facial expressions play a significant role in delivering your message. These non-verbal cues can help clarify meaning, show emotion, and give nuance to what you’re saying. Written communication lacks these elements. Words on a screen don’t carry tone or facial expressions, making it easier for the message to be misinterpreted. For instance, what you write with a positive intent could come across as neutral or even negative to the reader. WhyThe Importance of Effective Written CommunicationIn the realm of engineering management, the ability to communicate effectively is not just a nice-to-have skill; it’s a critical asset that can make or break projects and teams. Firstly, it’s often the foundation of remote and distributed work, serving as a record for accountability. Secondly, clear writing minimizes misunderstandings, saving time and resources. Thirdly, your written words set the team’s tone and culture, impacting motivation and work environment. Lastly, strong written communication skills enhance your reputation as an effective leader. Understanding these reasons gives you the motivation to improve, setting the stage for the practical tools and strategies that follow. WhatKey Components of Effective Written CommunicationMastering written communication in engineering management involves more than just joining words together. There are several crucial elements that make your messages effective, clear, and impactful. Intent is CrucialYour intentions should be transparent in any written communication. This is particularly important when delivering tough news or tasks. By clarifying your intent, you help the recipient understand the ‘why’ behind your message, which build trust and transparency, even in less-than-ideal situations. Instead of a vague, “The project will be delayed by two weeks,” you could write: “We’ve identified software bugs in the driver during the performance testing phase that impact the functionality of our feature, leading to a two-week delay in our project timeline. The goal of this message is to align and inform all our dependent teams. We are dedicating extra engineering resources to fix bugs and have scheduled an additional BugBash for November 21st. This is to ensure the highest quality before the upcoming release.” Context MattersIn any form of communication, context is key. Your reader doesn’t automatically know what you know; they only see what you’ve chosen to share in the written format. This limitation can lead to misinterpretations or misplaced emotions if the necessary background is lacking. In my early managerial role, I used to send messages that were consisted mainly of questions. For example, I’d ask, “Can you update me on Epic X?” or “Have we resolved the issue with the database?” While these questions were clear to me, they were often met with confusion or delayed response from my team. Without providing context—like I was accidentally creating a communication gap. It wasn’t until I started including additional information and background that I noticed a positive shift. When asking for an update on Epic X, I’d add, “We have a client meeting this Friday, and it would be great to demo the functionality provided by the Epic X” Or for the database issue, I might say, “The senior management is reviewing system performance next week, resolving this issue could impact their view positively on our team.” The Art of ToneAn intriguing but often overlooked aspect of written communication is the tendency for your words to shift in emotional weight when read by someone else. Understanding this can help you become more effective in conveying your thoughts and feelings accurately. Here’s what typically happens: Positive statements often become neutral: Your expressions of enthusiasm or happiness may not carry the same emotional punch in writing. For instance, a congratulatory “Well done on completing the project!” might just read like a standard acknowledgment to some. Neutral statements can be interpreted as negative: When you write something meant to be factual or impartial, there’s a risk it may be read with a more negative tone. A straightforward “Please send me the file” could be perceived as an impatient demand. Negative statements can become doubly negative: Negative expressions are especially susceptible to this. A remark like, “This needs improvement,” may be interpreted as, “This is unacceptable,” amplifying the emotional weight of your message. How do you feel when you read those message? Being aware of this tendency can help you make adjustments to your messaging style. It’s essential to go the extra mile to clarify your intent, making sure that your positive messages are overly positive, your neutral messages carry a hint of positivity, and your negative messages are cushioned with understanding and context. Emotional State of the ReceiverIt’s also equally important to consider the emotional state of the person on the receiving end. Your words don’t exist alone; they are processed through the lens of the reader’s current feelings, experiences, and concerns. If your team member is dealing with a personal crisis or even just had a rough day, their perception of your message can significantly differ from your intent. For example, a simple request for a status update could be seen as adding more pressure, making their day even more stressful. Taking a moment to understand the emotional climate can make a big difference in how your message is received. If possible, start your communication with a quick check-in or a brief acknowledgment of their situation. Something as simple as, “I understand you’ve had a busy day, but when you get a chance, could you update me on the project?” can set the right emotional tone. Acknowledging the emotional state of your receiver means communicating with empathy and awareness, which helps to build a foundation for more meaningful and effective interactions. Brief Messages and MicromanagementIn the quest for efficiency, it’s easy to use quick, command-style messages. For example, if you often say “my ask is” or frequently use commands like “do this,” “register here,” it can make you seem overly controlling or as if you don’t trust your team. Let’s see some examples: Example 1Let’s say you often tell your team, “My ask is to complete the report by end-of-day.” While you might think you’re being clear, your team may feel pressured. They might wonder why you’re focusing on “my ask” instead of the team’s shared goals. To avoid this, try rephrasing your requests to be more of a team effort. Instead of saying, “My ask is to complete the report,” you could say, “Could we aim to finish the report by end-of-day? It would help us make progress.” This way, you’re inviting teamwork and respect, without making the task seem less important. By paying attention to how you word your messages, you can be both clear and supportive, making sure your team feels encouraged rather than pressured. Example 2We all have moments where we need to send a message in a hurry. In such instances, you might be tempted to write something brief like, “Need update now.” However, without context, this can make the recipient anxious or defensive, interpreting the urgency as a sign of mistrust or dissatisfaction. Consider adding a sentence to offer context, especially when you’re pressed for time. For example, you could say, “Apologies for the brief message; I have only 2 minutes but wanted to check in. Need an update now, if possible.” This added context can transform the message from seeming demanding to being understood as a necessity of the moment. By including even a small amount of additional information, you offer the other person a chance to see things from your perspective. HowPractical Tools for Implementing Effective CommunicationThe Final CheckBefore hitting the ‘Send’ button, it’s beneficial to pause and review your message one last time. This final check serves as a practical tool to ensure you’ve communicated your intent and context clearly. Ask yourself these questions: Does the message sound demanding or negative? Have I overused certain phrases like “my ask”? Is the message clear and to the point? This filter not only helps you catch any mistakes or omissions but also offers a moment to gauge the emotional tone of your message. Especially when delivering news that could be perceived as negative or sensitive, this extra moment of scrutiny can make all the difference in how your message is received. By making the ‘Final Check’ a routine part of your written communication, you contribute to a more understanding and effective exchange of ideas. It takes only a few seconds but can save you from misunderstandings that take much longer to resolve. The Shift from Immediate Responses to Thoughtful Replies on SlackIn the early stages of my managerial role, I had the habit of responding immediately to Slack messages. While this might have appeared as a sign of being engaged and responsive, it often led to hasty replies that lacked nuance and thoughtfulness. Recognizing the downside, I shifted my approach. Instead of replying on the spot, I began to create draft messages first. This allowed me the opportunity to revisit them, add necessary context, or adjust the tone before sending. This approach served as a ‘safety net,’ ensuring my responses were well-considered. Eventually, I adapted this further. Now, I simply save messages that require a thoughtful response for later. I don’t even write draft responses. This gives me the time to assess the importance and context, allowing me to craft a message that provides value and clear communication when it’s finally time to send it. This change in habit, specific to Slack communications, has been a small but impactful step in enhancing the quality of my interactions with my team. It allows for better judgment and leads to more effective, meaningful communication. The Golden CircleYou may have noticed that this blog post is structured following the principles of The Golden Circle, a concept promoted by Simon Sinek. It began with the ‘Why,’ emphasizing the importance of effective written communication. We delved into the ‘What’ by discussing the key components that make your messaging clear and impactful. Finally, we explored the ‘How,’ offering practical tools and strategies you can implement immediately. By adopting Golden Circle format, my aim is to not just provide you with information but to truly engage with you on why this topic matters, what you can gain from mastering it, and how to go about it. This approach seeks to ensure a comprehensive understanding of the subject, thereby empowering you to improve your communication skills effectively. What IfAddressing Challenges and ExceptionsThe ‘What If’ section isn’t just about laying out possible scenarios and solutions; it’s also about understanding who your audience is. Knowing the people you’re communicating with allows you to better anticipate their questions, concerns, or even objections. By doing so, you can proactively address these in your ‘What If’ segment. Imagining how your message might be read or interpreted gives you the chance to clarify points that could be misunderstood. This level of audience awareness adds another layer of effectiveness to your written communication. It not only prepares you for various reactions but also offers a safety net for those who are reading your message, making the entire communication process more seamless and effective. Action PlanSteps to Improve Your Written Communication SkillsStep 1: Self-AssessmentIdentify areas where your written communication might be lacking. Is it in clarity, tone, or context? Step 2: Clarify IntentBefore writing, clearly outline what you want to achieve with your message. Make it a habit to restate this at the end of your communication. Step 3: Add ContextMake sure to provide background information when discussing projects or asking questions. A well-contextualized message minimizes misunderstandings. Step 4: Master Your TonePractice writing messages with a tone that matches your intended emotion. Reread your message, imagining how it would feel from the receiver’s perspective. Step 5: Emotional IntelligencePrioritize checking in on the emotional state of your message recipients, especially before delivering important or sensitive news. Step 6: Avoid Command-Style MessagingShift from issuing orders to inviting collaborative action. Use phrases like “Could we” instead of “I want.” Step 7: The Final CheckBefore sending, perform a quick review. Ensure clarity, tone, and context are appropriate. Step 8: Rethink Immediate Responses on SlackRather than replying instantly, draft your thoughts or save messages for later. Use this time to enrich your message with context and tone. Step 9: Utilize the Golden CircleEmbrace the ‘Why-What-How’ approach to structure your communications, be it emails, presentations, or meetings. Step 10: Prepare for ‘What If’ ScenariosKnow your audience well enough to anticipate questions or objections they may have, and address these proactively. ConclusionBy following these steps, you’re not just improving your written communication, but also fostering a culture of clarity and mutual understanding within your team. Each step is designed to build upon the previous, setting you on a comprehensive path to becoming an expert in written communication. Feel free to adapt these steps according to your own needs and experiences! Photo credit","link":"/2023/10/communication-written/"},{"title":"Count number of lines in project","text":"With combination of wc and find we can quickly count number of lines in our project: 1wc -l `find . -type f`","link":"/2012/01/count-lines/"},{"title":"Lessons learned from Decision Maker","text":"In the past few weeks, I’ve read Getting Things Done, Technical Leadership, Elon Musk Biography and The Decision Maker. Each of these books was good. But “The Decision Maker” is a game changer and I can’t stop thinking about this book. It was worth reading - for sure. I’ve decided to write a short book review and note the most important facts that I’ve learned from this book. ReviewThis book is a story about a company and its new owners who have left the corporation and decided to build a great place to work. It is full of dialogues, issues, and situations. By observing those scenes, the author presents ideas and values that matter when you have to lead the team or the company. Is this book only for managers or bosses? Certainly not. If you work with other people or deal with non-trivial tasks, this book is for you. For me, it is an appropriate supplement for any “Agile” book. Blueprint presented in this book is a good starting point for setting up company culture. The story did not take place in reality. Each scene looks genuine, but as a whole, it seems artificial. Like a romance from 90’s, when you know they will live happily ever after. PeopleTo begin with, you have to change your thinking about other people. People: are unique, are creative, are able to learn, have different strong points, have different needs, like a challenge, are capable of changing the environment, are capable of making contribution, can be trusted. Among some people, you can see those values. Among others, you have them hidden, and you have to unlock them. But there is always somebody who disagrees with it and this is important to remember it. Do you see any similarities with Theory X and Y employees? Decision MakerSecondly, you have to choose the Decision Maker. It is a person who makes a decision. How to find them? It is simple. The Decision Maker is a person, who is closest to the action. Bosses or leaders are not often deeply familiar with the situation. Usually, team members are often closer to the problem. The Decision Maker has to be capable of listening and understanding other people. Making a decision is a process, in which you have to talk and listen to the others. The Decision Maker should be aware of what is going on. Awareness of facts and consequences is crucial. If the person does not have basic data for making decisions - like company current finance status - you are responsible for unlocking that data. Wisdom and knowledge are desirable qualities of that person. It is a leader’s job to choose the Decision Maker. The leader should also observe and monitor the Decision Maker to see if he makes good decisions. If not, something should be done by the leader. Results of making decisionIt turns out that your employees’ decisions are often as good as or even better than yours can ever be. People who are allowed to make the decision feel the ownership, because of that they will do everything to make the best possible decision. Advisory processThe purpose of the advisory process is to look for a wider perspective.The Decision Maker should ask at least a few people what they think about the decision.He or she should ask: team members, other people with experience, subordinates and superiors, anyone who can help. But the Decision Maker should take the final call. Silver bulletThe decision maker process is not a silver bullet. It is only one tool or technique. The bigger picture is not straightforwardly visible in the book. Between the lines, you can see many behaviours and dialogues which look familiar in “Teal Organizations”. If your organization is not ready, the decision maker process is definitely not the road to follow. Photo credits:BannerThumbnail","link":"/2016/09/decision-maker/"},{"title":"Pierwszy post","text":"Cześć.Rozpoczynam pisanie swojego bloga.Zamierzam wyrażać swoje indywidualne podejście do świata techniki, urządzeń mobilnych oraz innych rzeczy.Dobrym pomysłem wydaje mi się opisanie na blogu, czegoś co udało mi się zrobić (w związku z programowaniem).Jeżeli kiedykolwiek w przyszłości będę się zastanawiał jak to zrobiłem, zaglądam na bloga i już wiem.Krytyka i wyrażanie własnych opinii będzie mile widziana. PozdrawiamMichał Lewandowski","link":"/2011/01/first-post/"},{"title":"Devoxx4Kids Poland 2014","text":"We did it. We did the first Devoxx4Kids Poland. For the last half year we worked very hard to prepare and organise this event. I would like to introduce co-organisers of this conference, Tomek Kucharski, Dariusz Kaczyński, Ewa Waliczek. Big thanks to them. I would like to thank Konrad Hoszowski and Eliza Kruczkowska for help. Also this event could not be possible without school and computer administrators from schools. Thank you! Big thanks have to go to Robomaniacs and Robocamp for preparing workshops. And of course this event could not be possible without our sponsors. We also receive help from 20 volunteers and two professional photographers. Thank you! We did eight parallel tracks for kids from 6 to 14 years old. They were four age groups. Each group have different T-shirt colour. There was a huge variety of topics. There were workshops related to hardware, software and mixed. We used Lego, Arduino and also games like minecraft. Visit devoxx4kids.pl for more informations. Do you want to organise this kind of event in your city? Email me, I would like to help you to start this kind of event in your city. Do you want to help in next year edition and join steering committee ? Email me.","link":"/2014/06/devoxx4kids-poland/"},{"title":"Fish shell - Load environment variables from file","text":"In many places, you can find environment files, with the following structure: 12FOO1=BAR1FOO2=BAR2 When you try to evaluate, this file using source command, you get an error with the fish shell. 12$ source web.env Unsupported use of '='. In fish, please use 'set FOO1 BAR1'. This is very annoying, so I’ve decided to write a function that can read this file and load those variables. Here is how you can use it: 123$ posix-source web.env$ echo $FOO1BAR1 The source code of this function. Enjoy: 1234567$ cat .config/fish/functions/posix-source.fish function posix-source for i in (cat $argv) set arr (echo $i |tr = \\n) set -gx $arr[1] $arr[2] endend Photo credits: Banner, Thumbnail","link":"/2016/10/fish-env/"},{"title":"CraftConf 2014","text":"There was a ticket to CraftConf to win on WJUG raffle. Maciek Górski win this ticket, but he couldn’t go, so he gave the ticket to me :) I was so happy to go to this conference. This was three days conference, one day of workshop, two days of university. The ticket I won was for university. At the moment there wasn’t any space left to register on workshop that I was interested in, so I wasn’t present at the workshop. The day before the conference, there was five meetups: Budapest Agile Meetup Group. Budapest Database And Big Data Meetup. Budapest DevOps Meetup. PHP Meetup Budapest. Frontend Meetup Budapest + UX Budapest. The speakers on those meetups were conference speakers. They must have very good communication between those groups and conference organisers, to organise those events :) My meet up was in ‘Prezi house of ideas’. Prezi is a company started in Budapest. They have great auditorium, for about 200 geeks, where you have place to eat pizza, drink bear all the time, beamer is ready to use and speakers just work. Lets look at the photo: I feel confused when I entered venue. There wasn’t any tips (arrows) on how to reach the registration desk. Next was the conference room that haven’t been signed. So on web page and on badges, there was order: MainRoom, Room1, Room2. In the venue there was three floors, so many people made an assumption that floor 1 is a MainRoom, floor 2 was room1, floor 3 was room3. It was wrong assumption because MainRoom was floor 2. After first session, arrows appeared on the wall’s. For me, it was only one thing that was bad on this conference. Let investigate conference bag. I have found, three good gadgets in conference bag: Headphones from e-pam. All conference session’s were transmitted online. If I wanted to switch the rooms, I used my computer and headphones to make a sneak peak preview of the other presentations and decide where to go. It was so great ! I did it only twice, because presentations was generally awesome. Phone cover from yahoo. It was raining all the time in Budapest, so this thing was great, because you could use your phone on the rain. Sugru from Google. So how about main room? 5 big screens. One for slides, two for camera, two for twitter. Makes an impression. For questions to the speech we used sli.do. Whole event was led by one person, who did it great. I remember following sponsors talk Ericcson, Misys, Yahoo, T-Mobile, JetBrains, Epam and maybe more, but I fall asleep. One more fact. 20% of the speakers was woman. Great achievement. I make about 500 lines of notes. I think I never noted more before. I probably never ever read them again, but this help me remembering things. I can distinguish three kinds of topics that was on conference. First are about motivation, passion, craftsmanship. Those kind of of lectures makes you to think about why you do. Second group of talks were about architecture or similar things. Those kind of of lectures makes you to think about how you do. Third group of talks where about specified technique or technology. Those kind of of lectures makes you to think about, what you do. Talks are becoming available at: uStream. If somebody ask me to pick three best lectures (except keynotes) I will point at: Jackstones: the journey to mastery - Dan North (Dan North &amp; Associates) How I Learned to Stop Worrying and Love Flexible Scope - Gojko Adzic (Neuri Consulting LLP) Functional Reactive Programming in Elm and JS - Evan Czaplicki (Prezi) You may ask, why those three? First two are simply great in every word. The third is about passionate speaker. Im do not like front-end and things like that. But Evan, when he presented Elm language, there was a message “I believe in what I am doing” and it was great. How about networking ? I met geeks from Finland, Germany and even from Australia. After parties helps with this a lot :) To summarize. Why to go to CraftConf 2015? Because this conference is a good therapy session. Photo credit","link":"/2014/04/craft-conf-2014/"},{"title":"Functional Programming in Java","text":"Harnessing the Power of Java 8 Lambda ExpressionsVenkat SubramaniamMy new year commitment was, that I read one book each month. I don’t predicted an unexpected events that may me slow down :( I do not give up. Next book review will be in 16’th of April. About the book. I’ve read a beta 6 edition from 13 of January, but I think that final version is very similar to the this beta version. It is not the book about Java 8. It is a book about Lambda Expressions in JDK8. The title says that. In JDK8 there are for example changes in GC. I was missing at least one chapter or few pages about it. It was book easy to understand. I have Groovy and Scala experience, so there was nothing new to me. All the time I was mapping Java code to Scala code :). It was good for me. Next good thing is that it reads like a group of blog posts. We have some examples of imperative style, then we move to declarative or functional style. Size of chapters was appropriate for me to read before sleep. I didn’t like code examples (not in book, but downloadable code). Code examples was without tests and assertions. Just run and print output. I like BDD tests, and it will be great to read examples that are combined with BDD tests. I would recommend this book to a friend, because it is focused on good developer practices. Photo Credit","link":"/2014/03/functional-programming-venkat/"},{"title":"Gerrit and maven release plugin","text":"There is a time in your project when you start using Gerrit code review system. When you have maven release plugin to make release, you can be very surprised when you see: 123[ERROR] The git-push command failed. [ERROR] Command output: [ERROR] Permission denied (publickey). This is a situation when we use ssh connections to gerrit. But, when you try to push something to master (ignoring code review), it works! How is that possible? You probably have in your gitconfig an ssh URL with your user name. But in your project SCM (in pom.xml) you do not have your user name. What user name maven release plugin use? Your computer account name, which is in most cases different than your Gerrit user name. How to repair it? Define a file in .ssh/config directory with content: 1234Host gerrit HostName YOUR_GERRIT_HOST Port YOUR_GERRIT_PORT User YOUR_GERRIT_USER_NAME There may be a lot of other reason why you have Premission denied, but this was the hardest I’ve ever seen.","link":"/2015/01/gerrit-maven-release-plugin/"},{"title":"Listing files in Git","text":"Exploring git ls-filesThis post describes, my experiments with git ls-files command. In repository, we have files: File structure in repository1234567.DS_Store (Mac OS X, folder settings file).git (Git repository file).gitignore (Git ignore file)ignoredFile (Some file, that should be ignored)inRepo (File in repository)untracked (Som untracked file)staged (Staged file) This command show us, all committed files and staged files. List files1234$ git ls-files.gitignoreinRepostaged This command show us, all files that are ignored or untracked. Those files are called ‘other’. List ignored or untracked1234$ git ls-files --others.DS_StoreignoredFileuntracked This command show us, all others files, without ignored files. Option exclude-standard means that standard git exclusion files are included. List others files, without ignored files12$ git ls-files --others --exclude-standarduntracked This command show us, all files that are ignored. List all ignored files123$ git ls-files --ignored --others --exclude-standard.DS_StoreignoredFile In my global git ignore file, there is a rule to ignore all .DS_Store files. In my local git ignore file, there is a rule to ignore ignoredFile file.","link":"/2013/07/git-ignored-files/"},{"title":"Formatting Java Time with Spring Boot using JSON","text":"The aim of this post is to summarize and review ways of formatting Java Time objects using Spring Boot and Jackson library. This post is organized in five steps. Each step represents one aspect of the issue and it is also related to one commit in example project repository. Step 0 - PrerequirementsVersions and dependenciesThis tutorial is based on Spring Boot version 1.3.1.RELEASE with spring-boot-starter-web. It uses jackson-datatype-jsr310 from com.fasterxml.jackson.datatype in version 2.6.4, which is a default version of Spring Boot. All of these is based on Java 8. The CodeIn the example code repository, you can find one HTTP service made with Spring Boot. This service is a GET operation, which returns a class with Java Time objects.You can also find the integration test that deserializes the response. Step 1 - The goalI would like to return class Clock, containing LocalDate,LocalTime and LocalDateTime, preinitialized in constructor. Clock - Service response class123456public final class Clock { private final LocalDate localDate; private final LocalTime localTime; private final LocalDateTime localDateTime; ...} Response class is serialized to JSON Map, which is a default behaviour. To some extent it is correct, but ISO formatted Strings in response are preferable. LocalDate - response as JSON Map12345678910111213141516{ &quot;localDate&quot;:{ &quot;year&quot;:2016, &quot;month&quot;:&quot;JANUARY&quot;, &quot;era&quot;:&quot;CE&quot;, &quot;dayOfYear&quot;:1, &quot;dayOfWeek&quot;:&quot;FRIDAY&quot;, &quot;leapYear&quot;:true, &quot;dayOfMonth&quot;:1, &quot;monthValue&quot;:1, &quot;chronology&quot;:{ &quot;id&quot;:&quot;ISO&quot;, &quot;calendarType&quot;:&quot;iso8601&quot; } }} Integration testing is an appropriate way to test our functionality. Example of integration test123456ResponseEntity&lt;Clock&gt; resp = sut.getForEntity(&quot;http://localhost:8080/clock&quot;, Clock.class);assertEquals(OK, resp.getStatusCode());assertEquals(c.getLocalDate(), resp.getBody().getLocalDate());assertEquals(c.getLocalTime(), resp.getBody().getLocalTime());assertEquals(c.getLocalDateTime(), resp.getBody().getLocalDateTime()); Unfortunately, tests are not passing, because of deserialization problems. The exception with message is thrown can not instantiate from JSON object. Step 2 - Adds serializationFirst things first. We have to add JSR-310 module. It is a datatype module to make Jackson recognize Java 8 Date &amp; Time API data types. Note that in this example jackson-datatype-jsr310 version is inherited from spring-boot-dependencies dependency management. Dependency in pom.xml1234&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt; &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt;&lt;/dependency&gt; Response is now consistent but still, not perfect. Dates are serialized as numbers: Dates serialized to numbers and integers1234567891011121314151617181920{ &quot;version&quot;:2, &quot;localDate&quot;:[ 2016, 1, 1 ], &quot;localTime&quot;:[ 10, 24 ], &quot;localDateTime&quot;:[ 2016, 1, 1, 10, 24 ], &quot;zonedDateTime&quot;:1451640240.000000000} We are one step closer to our goal. Tests are passing now because this format can deserialized without any additional deserializers.How do I know?Start an application server on commit Step 2 - Adds Object Mapper, then checkout to Step 1 - Introduce types and problems, and run integration tests without @WebIntegrationTest annotation. Step 3 - Enables ISO formattingISO 8601 formatting is a standard. I’ve found it in many projects. We are going to enable and use it.Edit spring boot properties file application.properties and add the following line: application.properties file - disabling timestamps write1spring.jackson.serialization.WRITE_DATES_AS_TIMESTAMPS = false Now, the response is something that I’ve expected: Dates serialized as Strings1234567{ &quot;version&quot;:2, &quot;localDate&quot;:&quot;2016-01-01&quot;, &quot;localTime&quot;:&quot;10:24&quot;, &quot;localDateTime&quot;:&quot;2016-01-01T10:24&quot;, &quot;zonedDateTime&quot;:&quot;2016-01-01T10:24:00+01:00&quot;} Step 4 - Adds on demand formatting patternImagine one of your client systems does not have a capability of formatting time. It may be a primitive device, or microservice that treats this date as a collection of characters. That is why special formatting is required. We can change formatting in response class by adding JsonFormat annotation with pattern parameter. Standard SimpleDateFormat rules apply. Using @JsonFormat annotation12345@JsonFormat(pattern = &quot;dd::MM::yyyy&quot;)private final LocalDate localDate;@JsonFormat(pattern = &quot;KK:mm a&quot;)private final LocalTime localTime; Below there is a service response using custom @JsonFormat pattern: Custom response style1234567{ &quot;version&quot;:2, &quot;localDate&quot;:&quot;01::01::2016&quot;, &quot;localTime&quot;:&quot;10:24 AM&quot;, &quot;localDateTime&quot;:&quot;2016-01-01T10:24&quot;, &quot;zonedDateTime&quot;:&quot;2016-01-01T10:24:00+01:00&quot;} Our tests are still passing. It means that this pattern is used for serialization in service and deserialization in tests. Step 5 - Globally changes formattingThere are situations where you have to resign from ISO 8601 formatting in your whole application, and apply custom made standards. In this part, we will redefine format pattern for LocalDate. This will change formatting of LocalDate in every endpoint of your API. We have to define: DateTimeFormatter with our pattern. Serializer using defined pattern. Deserializer using defined pattern. ObjectMapper bean with custom serializer and deserializer. RestTemplate that uses our ObjectMapper. Bean ObjectMapper is defined with annotation @Primary, to override default configuration.My custom pattern for LocalDate is dd::MM::yyyy Object mapper bean with custom pattern1234567891011121314public static final DateTimeFormatter FORMATTER = ofPattern(&quot;dd::MM::yyyy&quot;);@Bean@Primarypublic ObjectMapper serializingObjectMapper() { ObjectMapper objectMapper = new ObjectMapper(); JavaTimeModule javaTimeModule = new JavaTimeModule(); javaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer()); javaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer()); objectMapper.registerModule(javaTimeModule); return objectMapper;} Definitions of serializer and deserializer for all LocalDate classes: Custom serializer and deserializer123456789101112131415public class LocalDateSerializer extends JsonSerializer&lt;LocalDate&gt; { @Override public void serialize(LocalDate value, JsonGenerator gen, SerializerProvider serializers) throws IOException { gen.writeString(value.format(FORMATTER)); }}public class LocalDateDeserializer extends JsonDeserializer&lt;LocalDate&gt; { @Override public LocalDate deserialize(JsonParser p, DeserializationContext ctxt) throws IOException { return LocalDate.parse(p.getValueAsString(), FORMATTER); }} Now, the response is formatted with our custom pattern: Formatted response123{ &quot;localDate&quot;:&quot;01::01::2016&quot;} TestsWhen we define custom serializer, our tests start to fail. It is because RestTemplate knows nothing about our deserializer. We have to create custom RestTemplateFactory that creates RestTemplate with object mapper containing our deserializer. Custom RestTemplateFactory1234567891011121314151617@Configurationpublic class RestTemplateFactory { @Autowired private ObjectMapper objectMapper; @Bean public RestTemplate createRestTemplate() { RestTemplate restTemplate = new RestTemplate(); List&lt;HttpMessageConverter&lt;?&gt;&gt; converters = new ArrayList&lt;&gt;(); MappingJackson2HttpMessageConverter jsonConverter = new MappingJackson2HttpMessageConverter(); jsonConverter.setObjectMapper(objectMapper); converters.add(jsonConverter); restTemplate.setMessageConverters(converters); return restTemplate; }} ConclusionCustom formatting Dates is relatively simple, but you have to know how to set up it. Luckily, Jackson works smoothly with Spring. If you know other ways of solving this problem or you have other observations, please comment or let me know. Photo credits: Banner, Thumbnail","link":"/2016/02/formatting-java-time-with-spring-boot-using-json/"},{"title":"Fest Assert","text":"On 9’th of Aprill 2013, I’ve done a presentation on Warsaw Java User Group about Fest Assert. A library that helps us made better assertions. Here is the video on youtube and slides. Photo Credit - Festival","link":"/2013/04/fest-assert/"},{"title":"GeeCon 2014","text":"I’ve spent the last three days on GeeCon 2014. I must say I become demanding when I go to conference, so my opinion is becoming more critical. Basically the conference was good. There was small problems with WiFi, venue wasn’t in the city center (imagine 1000 peoples ordering taxi or getting to the local bus), but generally it was ok. Most of the talks were good. There is one thing, that I am really happy about. I made a lot of new connections. This is the aspect that push me to the next edition of GeeCON :) I really enjoyed the afterparty at ‚Stara Zajezdnia’. This place is a local brewery, so we drunk very good beer. Also we had opportunity to take a tour with experienced brewer, so I also learned new things about brewery. Thus GeeCoin game, I also meet new people ;p There was not any feedback system, so this is my feedback. Lets make an talk about hobbies or very light topics which will take 30 minutes after the dinner. I would like to listen about how take care of you health when working all days with computer, how to make a beer, something about motorization or photography. I need a longer break after the diner with soft topic. I’ve selected talks, that I think was good and which I would recommend for my friends (excluding keynotes): All Sam Newman talks about microservices. Just must watch or read a book. Josh Long talk about Spring, because live demo was exploding with energy. Tom Bujok with ’33 things you want to do better’, but only the first part. Second part was to obvious for java developer with some experience. Kevlin Henney with ‚Seven Ineffective Coding Habits of Many Java Programmers’ for great preparation of content. Thats it. See you next year.","link":"/2014/05/geecon-2014/"},{"title":"Groovy Recipes by Scott Davis","text":"CommitmentMy new year commitment is to read a book every month and write a review on this blog BookSo the first book is Groovy Recipes by Scott Davis. This book was easy to read. I read it fast. Very fast. Mostly because I know more or less about Groovy. There was one maybe two things that was new to me. So I think this book w is not good for developers with some Groovy experience. Besides that book was very well organized. In each chapter we could find answer to to the problem related to chapter title. This book need an update. It was written in 2008. A lot changed since then. For example maven building style. I will definitely recommend this book to my friends who would like to start using Groovy quickly. My rate is 4 of 5 starts.","link":"/2014/02/groovy-recipes/"},{"title":"New methods in Map.Entry comparingByKey and comparingByValue","text":"JDK 8 is still new and hot. I have explored some new methods in Map.Entry interface, to sort objects. Image that we have following collection: Initial data12345Map map = new HashMap&lt;&gt;();map.put(&quot;Kawasaki&quot;, 3);map.put(&quot;Honda&quot;, 1);map.put(&quot;Norton&quot;, 5);map.put(&quot;Moto Guzzi&quot;, 2); There are four new methods: comparingByKey() comparingByKey(Comparator&lt;? super K&gt; cmp) comparingByValue() comparingByValue(Comparator&lt;? super K&gt; cmp) The method names are self-describing. If we pass different comparator, we can get different behaviour. Comparing by valueIf we want to sort by value with default behaviour (ascending), we can do something like this: ComparingByValue1234567List&lt;Map.Entry&lt;String, Integer&gt;&gt; comparingByValue = map.entrySet().stream().sorted(Map.Entry.comparingByValue()).collect(Collectors.toList());comparingByValue.forEach(System.out::println); As a result, we get a list sorted by values: 1234Honda=1Moto Guzzi=2Kawasaki=3Norton=5 Comparing by keyIf we want to sort by key with default behaviour (ascending), we can do something like this: ComparingByKey1234567List&lt;Map.Entry&lt;String, Integer&gt;&gt; comparingByKey = map.entrySet().stream().sorted(Map.Entry.comparingByKey()).collect(Collectors.toList());comparingByKey.forEach(System.out::println); As a result, we get a list sorted by keys alphabetically: 1234Honda=1Kawasaki=3Moto Guzzi=2Norton=5 Comparing by key with comparatorIf we want to sort by key length, we can pass function as a comparator, Then we can achieve something like this: ComparingByValue with comparator1234567List&lt;Map.Entry&lt;String, Integer&gt;&gt; comparingByValue = map.entrySet().stream().sorted(Map.Entry.comparingByKey((String s1, String s2) -&gt; s1.length() - s2.length())).collect(Collectors.toList());comparingByValue.forEach(System.out::println); As a result, we get a list sorted by keys length: 1234Honda=1Norton=5Kawasaki=3Moto Guzzi=2 Photo credit","link":"/2014/04/java8-map/"},{"title":"Trigger Jenkins build from BitBucket","text":"W tym poście przedstawię jak zrobić, aby natychmiast po wypchnięciu zmian do BitBucket.org serwer ciągłej integracji rozpoczął proces budowania aplikacji. Konfiguracja Jenkinsa W związku z tym, że nasz Jenkins musi być dostępny publicznie, warto go trochę zabezpieczyć. Dostęp do Jenkinsa ograniczymy tylko dla zarejestrowanych użytkowników. Opcje konfiguracji zabezpieczeń powinny być ustawione tak jak na screenie poniżej. Nazwa użytkownika w tym przypadku to “lewy”. Następnie musimy pobrać nasz “user API token”. Znajdziemy go tutaj: Następnie musimy włączyć dla naszego projektu, możliwość zdalnego triggerowania budowania: Aby przetestować konfigurację Jenkinsa wywołaj zapytanie do serwisu: http://lewy:USER_KEY@klkl.pl:8081/job/WorkTracker/build?token=PROJECT_KEY Po wykonaniu tej operacji, nasz serwer Jenkinsa powinien ruszyć z nowym procesem budowania. Konfiguracja BitBucketaBitBucket’a konfigurujemy tak jak na screenie przedstawionym poniżej: Jeżeli tak skonfigurujemy nasze środowisko, po pchnięciu zmian, serwer ciągłej integracji, powinien automatycznie rozpocząć budowanie aplikacji. Niestety BitBucket nie udostępnia żadnych logów, więc jeżeli coś nie działa, to pozostaje nam próbować zmieniać coś w ciemno, aż zadziała.","link":"/2013/02/jenkins-bitbucket/"},{"title":"Why you should attend Jitter on MCE?","text":"Jitter workshop event is a part of Mobile Central Europe Conference. It is a one day event full of attractions. Each workshop is repeated, so you can attend to two different workshops. So why, you should attend Jitter? You can meet cutting edge technology like Emberlight or Wunderbar. You can co operate with you new friends to do amazing stuff. I have an opportunity to take part in “Cardboard Design” workshop, where mentors where Wiesław and his friends. We were working in groups. Our goal was to visualise music using arduino, few servomotors and of course cardboards. We totally unleashed our imagination. Effects was amazing. We have used 100% of our creativity. Besides that, event took place in a film studio. Raw and unpolished style. It give me more energy to work. But, there was a few defects. It was loud and cold, but organisers do everything to minimize those effects. I am definitely looking forward for next Jitter on next year MCE","link":"/2015/02/jitter-mce/"},{"title":"Impact Mapping","text":"Making a big impact with software products and projects - Gojko AdzicBefore I read this book, I was on Impact Mapping workshop by Krzysztof Jelski on Agile By Example. I knew the concept. I practiced it in my company in one internal project. I am going to use it in next project with client. But now. About the book. The book is very good. The knowledge in this book is very concise. Which was good for me, but may be problematic for person who does not know the topic, because important parts may be missed. Because the book has a lot of condensed knowledge, I’m going to read it again. I found things not directly related to impact mapping. For example chapter about iterative and incremental software building process. I liked chapters, which were abstracts of other peoples thoughts, for example Tom Gilb about metrics. It is an advantage. I like the idea that the concept of impact maps has been described without going into unnecessary detail. This book is some kind of guideline, blueprint. And this is good. And the most important chapter for me was “Typical mapping mistakes”. It allowed me to find a place, where I do something bad (I was unaware of it). Apart from book. I asked myself, why we do impact maps? One of the main reasons is to create good channel of communication. To create a big picture view for technical and business people. Second reason is to decide, what should be built to achieve our goal, to reduce waste and over-engineered solutions. I strongly recommend this book and to try this technique. Photo credit","link":"/2014/04/impact-mapping/"},{"title":"Outcome vs Output in Software Engineering - A Critical Balance","text":"Imagine a skilled craftsman meticulously building a wooden chair. The finished chair, sturdy and polished, is the output. But if nobody finds the chair comfortable, the intended outcome, a satisfying seating experience, is not achieved. This simple example from carpentry resonates deeply with the complex world of software engineering. Have you ever heard of o Software Engineer who does not like to be named Craftsman? The nuance between outcome and output is not philosophical and has profound practical implications. As software engineers, focusing on both aspects can lead to projects that are not only technically sound but also aligned with user needs and business goals. Output and OutcomeThe Output of Software EngineeringWhat is Output?Output in the software engineering context refers to the tangible products or deliverables at various stages of development. Examples: Writing a new algorithm to ingest data Completing a software module responsible for customer authentication Fixing a set number of bugs Short-term goals align well with immediate targets and development sprints. Focusing solely on outputs may lead to missing the bigger picture or neglecting user satisfaction. The Outcome of Software EngineeringWhat is Outcome? Conversely, the outcome emphasizes the broader impacts of those outputs, focusing on how the end-users interact with the software or how it impacts the overall organizational goals. Examples: Enhancing user experience &amp; satisfaction. Increasing customer retention &amp; connection with the product. Outcomes often correlate with the product’s ultimate goal, aligning activities with overarching objectives. The hardest part of outcomes is ensuring the software meets the real needs of the users. Often outcomes may require a long time to materialize and might be multifaceted - but not always. In my career, I found that small changes (in the processes or code) may produce significant outcomes. When to say that an outcome is not delivered? For example, when the users love the product, engineers are elated about the code, but the product generates a loss, for example, when the cost of running it is too high. Managing output vs outcomeThe Challenge of Balancing Output and Outcome for Software EngineersSoftware engineers often need help balancing immediate outputs and broader outcomes due to the inherent complexities and conflicting priorities in software development. On the one hand, there’s pressure to deliver tangible results quickly, such as completing specific features or meeting sprint deadlines, which emphasizes the output aspect. On the other hand, the broader outcomes, like enhancing user satisfaction or aligning with strategic goals, require a more nuanced understanding of the end-users needs and the organization’s long-term vision. This can necessitate careful planning, collaboration with various stakeholders, and continuous feedback and iteration. Striking the right balance demands technical proficiency, strategic thinking, empathy towards users, and a precise alignment with project-level objectives and organizational goals. Whose Role Is It to Keep the Balance?Maintaining the balance between immediate outputs and broader outcomes is a shared responsibility that involves multiple stakeholders within the software development process. While software engineers are at the core, ensuring that their work aligns with both short-term deliverables and long-term goals, project managers and product owners play a vital role in defining clear expectations and keeping the focus aligned with overall objectives. Ultimately Engineering Managers and product owners are responsible for the product. How to distinguish Junior Engineer from Senior Engineer? The difference is that the first should focus mainly on outputs, while the former should focus more on the outcome.Nevertheless, achieving this balance is a collective effort that requires clear communication and alignment across different roles. Performance Rating of Software Engineers: An Outcome and Output PerspectiveBecause of my role as an Engineering Manager, I’ve to asses engineers’ work. In evaluating a software engineer’s performance, both outcome and output can play distinct roles. Traditionally, performance might be assessed based on tangible outputs such as the number of features developed or bugs fixed. While these metrics provide a clear and measurable way to gauge productivity, they can sometimes overlook the broader impact and alignment with organizational goals – the outcomes. I believe the solution is the balance. Balancing both output-oriented metrics and outcome-driven evaluation ensures a more holistic understanding of an engineer’s performance, rewarding the quantity of work, quality, and contextual relevance. This approach promotes a culture that values meaningful contributions and encourages engineers to strive for excellence that resonates with immediate tasks and broader organizational vision. Strategies to BalanceBalancing output and outcome requires a thoughtful and multifaceted approach that combines various strategies. Agile Methodologies can be leveraged to ensure iterative development that values immediate deliverables and alignment with end-user needs. Regular Communication among team members, product owners, and stakeholders helps keep everyone on the same page, emphasizing short-term goals and long-term vision. I want to focus on something other than each specific methodology, like Scrum or Kanban, because all those methodologies assume constant feedback to the process. Adapting to the circumstances is the most crucial skill both companies and people can practice. Customer-Centric Development, including regular feedback and user testing, ensures that outputs are geared towards satisfying real user needs, thus aligning outputs with desired outcomes. Concluding Thoughts“The operation was a success, but the patient died.”The phrase grimly illustrates a situation where the immediate task was completed (the operation or output). Still, the ultimate goal was not achieved (the patient’s survival or outcome). In software engineering, creating a technically flawless piece of software (successful operation) that fails to meet the users’ needs or business goals (patient died) is quite often. This underscores the critical importance of balancing output and outcome. While outputs are essential for measuring progress and achieving immediate goals, outcomes preserve the process’s broader vision, good software, and user satisfaction. Appendix: Polish TranslationsIn Polish, we also have two separate words to distinguish between Output and Outcome. Output is translated as “wynik”. Outcome is translated as “rezultat”. Understanding these nuances in translation is crucial, especially when discussing matters in a business or technical context in Polish. This ensures that the intended emphasis, whether on immediate deliverables or broader implications, is clearly communicated and understood. Photo credit","link":"/2023/08/output-vs-outcome/"},{"title":"GNU sed and xpath on OS X","text":"In my team, there is 20% of OS X machines, rest are linuxes. We share one script, that everyone on our team uses. That script was written by some guy on Ubuntu and guess what? GNU versions of those programs (sed and xpath) are not compatible with BSD versions. The script was failing :( I was trying to improve the script, but forget about it. Just use GNU programs. To install gnu sed on osx via homebrew type the following: GNU Sed1brew install gnu-sed --with-default-names To install gnu xpath on osx via homebrew type the following: GNU Xpath1234brew tap concept-not-found/tap brew install xpath mv /usr/local/bin/xpath /usr/local/bin/osx.xpath sudo ln -s /usr/local/Cellar/xpath/1.13-7/bin/xpath /usr/local/bin/xpath","link":"/2015/01/sed-xpath/"},{"title":"Korekta pisowni w Chrome - Snow Leopard","text":"Chrome w swojej przeglądarce chciało być fajne i ustawia język korekty pisowni na podstawie ustawień systemowych.Mój domyślny język systemowy to angielski, natomiast korekta pisowni w systemie to polski.Chrome tego nie ogarnia i ustawia korektę na angielski co powoduje, czerwone szlaczki w polach tekstowych na stronach.Przedstawię sposób na ręczny wybór korekty pisowni w Google Chrome na OS X. Wyłącz ( CMD+Q ) Chroma Edytuj plik: File path1~/Library/Application\\ Support/Google/Chrome/Default/Preferences Dodaj nową sekcję: Spellcheck1234&lt;pre name=&quot;code&quot;&gt;&quot;spellcheck&quot;: { &quot;dictionary&quot;: &quot;pl-PL&quot; } &lt;/pre&gt; Pamiętaj o tym, żeby postawić przecinek w poprzedniej sekcji. Zapisz i uruchom przeglądarkę. Powinieneś otrzymać taki rezultat: Jeżeli dodałeś sekcję na końcu, po uruchomieniu Chrome, cały plik zostanie posortowany alfabetycznie, więc będzie wyglądało to mniej więcej tak: Spellcheck1234567 &quot;restore_on_startup&quot;: 1},&quot;spellcheck&quot;: { &quot;dictionary&quot;: &quot;pl-PL&quot;},&quot;sync&quot;: {... } Zamiast pl-PL możemy ustawić en-EN lub puste pole aby całkowicie wyłączyć korektę.","link":"/2011/01/snow-leopard-spellcheck/"},{"title":"Software Engineer Checklist","text":"When I started my career as a software engineer, I didn’t have any map or list of skills that are necessary to succeed. I’ve spent too much time on unimportant stuff, a far too little on crucial things. If you know at least something about software development - you can create web service in Django, or build microservice in Spring, crate some machine learning model, or write Spark Job - and you want to advance your career to the next level, this blog post might be helpful for you. Before we start, I have good and bad news.The good news is that at some point you will have to unlearn what you have learned. If you learn something, you are becoming blind to other things that you can learn. Remember, you are a creative person; your mind should be free and open for new waters. Do not be afraid to forget stuff. The bad news is that you will probably never stop learning.Over time, some things became similar, and we use similar design patterns in different contexts. Even that something is similar, it is not an excuse to stop learning. You need thousands of hours of practice and writing software to be good at it. Besides spending many years writing software, I know that I have deficiencies in some areas that I want to improve. DisclaimerI’ve tried to build this competence area map to be as universal as possible. Nevertheless, I realize that backend software engineers found it applicable, whether other specializations may found it less useful. If any of those concepts are new for you, do not try to learn everything in one week. Learning about software engineering is like going down the rabbit hole. You think that you get it, but then you realize that there is another level of abstraction or other stuff to discover. If you are a person who likes following the rabbit holes, this guide may be for you. Original ideaIt all started with writing down the desired competency list for myself a few months ago. In the same way, many of us do a medical examination, and I wanted to do my professional skillset examination. I did it in Google Sheets. The total number of rows that I’ve written was 50 - each describing skill, knowledge area, or competence that I want to build or improve in myself. Hard technical skillsHard technical skills are a necessity when you are a software developer. While I was writing down technicals skills, I divided them into three groups: General. Those are universal skills that benefit you for many years. Understanding them is an important thing. Support. Although those skills are not necessary to do your job rightly, by having those skills, you gain a deeper understanding and be able to propose more suited solutions. Trendy. The IT profession is susceptible to trends. Today we use that technology, but tomorrow we may use different. General technicalGeneral technical skills are skills that are not going to be outdated promptly. On the other hand, practicing those skills consumes much time, and in my opinion, you need years to practice them, rather than months. Algorithms. I often get alarmed whenever I hear that someone is stating that “Learning algorithms is a waste of time.” Studying algorithms is the essential thing that you can do when you learn computer science. Algorithms are everywhere. Algorithms are often quite different from one another. By studying more and more algorithms, you may develop different solutions for the problems which arise during a regular job. I have to admit that I learn mostly from my experience. Studying algorithms is an eye-opener for new approaches on how to solve things. If I hadn’t studied algorithms, I would propose worse code, simply because I wasn’t familiar with some techniques. Data structures. Each data structure is designed to arrange data to suit a specific purpose. Sometimes we want to find data quickly or store quickly. Knowing fundamental data structures, like Hash Maps or Trees, is a necessity. Also, it is vital to be familiar with more advanced data structures like probabilistic data structures, immutable data structures, or when we talk about BigData - distributed data structures. Programming. Can you write code in your primary programming language without an IDE (Integrated Development Environment)? Can you do that using only a text editor and compiler? Without knowing language syntax, builtin libraries, data structures, fundamental data types, it is impossible to be productive. Although I use IDE on my daily basis, it provides me little to none help when it comes to solving simple and primitive code mistakes. Framework. Can you write code without using StackOverflow? My primary programming framework is Spring Framework. Things like exposing an API, fetching data from a database, calling other services using HTTP Client, writing unit tests, are natural for me because I am familiar with this framework. If you need to Google everything you need to do and copy-paste the solutions - especially simple tasks - you are probably not familiar with your framework. Architecture. It is easy to understand, maintain, and develop a system with clean and transparent architecture. There is no silver bullet here. You have to know at least a few architectural styles to communicate your ideas, and to understand others. You have to understand the basic concepts. When someone is saying to you, “Event sourcing is ideal for this problem.” you need to be on the same page to discuss details of that architectural style. Database. In the initial steps of designing a new system, a database might be a nonrelevant detail to your application architecture. Sooner or later, the database is an element that cannot be ignored. Embrace the polyglot database style. Analyzing database queries, managing indexes, configuring partitioning, and replication is a piece of must-have knowledge. There are far too many different databases on the market to know each well, but you have to know one database at least well and know when to use which database. Design patterns. If your primary language is object-oriented, you have to know basic design patters (reading a book about design patterns may help). Besides that, there are also more rules, like SOLID, KISS, DRY. There is also DDD and CQRS, which are more like architecture styles. Use those patterns, but do not overuse them. Coding styles. There are different approaches on how to write code. There is TDD (Test Driven Development), Test First Approach, Pair programming, writing PoC (proof of concept), or writing scripts for one-time use. Each of these styles aims to achieve different things. Try different things and know the advantages and disadvantages of different approaches. Concurrency, no wonder, is the scariest topic for many developers. It’s hard to test, debug, and reason. Not only you have to understand the behavior of concurrent programming in your language, but you also need to understand your platform well. For example, take JVM. At first glance, you download it, and it works. For me, this is a typical example of a rabbit hole. You have to investigate the Java Memory Model, Garbage Collection, Just-in-time compilers, bytecode. You can not study it in just one day. It may take you weeks to investigate all this stuff. Tests. There are many different tests that you can write for your code: Unit tests, Integration tests, End to End tests, Chaos testing, mutation testing. It is easy to write test code, but the tricky part is maintaining the test codebase in vital conditions. Test code should be treated with the same importance as your production code. Remember that if you have robust and reliable tests, you can rewrite your production code without any bother. CI and CD. I don’t pay much attention, whether it is Jenkins, Bamboo, or GitLab CI. Pick one, and know it well. Understanding why we do Continues Integration or Continues Development is an important aspect. The tool does not matter. The right configuration to achieve the right goals is crucial. Security. This a vast topic. Essential is asymmetric cryptography (public/private key), authentication methods, access delegation methods - OAuth. On the other hand, you have to know different vulnerabilities (like SQL Injection or Cross-Site Scripting). Then it is essential to realize what types of malware there are and what are the root causes of exploits. And last, you have to know your technology stack, to design and build safe applications. Network communication. The first thing to know is “8 fallacies of Distributed Systems.” It helps you to understand the behavior of a network application and characteristic of network communication. Then, digging deep into the network stack helps you understand network communication via modern protocols and debug problems, which sooner or later happen. Rapidity. Practice, practice, practice until you achieving fluency in general programming. After a few years in software development, you should be able to swiftly develop a new application, fix a bug, or re-engineer a complete system. Anyone can probably write any system, given no time limit. SupportingSupporting skills are skills that are not your core competence. Instead, knowing those things helps you see the complete spectrum of the Software Engineer Toolbox. Although you do not have to be an expert in each aspect, you have to be familiar with each aspect, and be able to develop something in other areas. Distributed systems. Truth be told, I don’t think that I will ever write a system that runs on a single computer. Because we are not able to build faster CPUs and single machines in general, it is reasonable to host your services on commodity class machines or in a cloud in a shared environment. We all need to understand how to design, develop, and maintain a distributed system. Statistics and math. I noticed that I often use mathematical statistics concepts, which I learn in School. It is Percentiles, standard deviation, quartiles, mean, distribution. I use it all the time, for example, in analyzing service response times or working with almost any kind of data. BigData. It is good to have some experience with Hadoop, Spark, Job Scheduling mechanism (like Airflow), Stream processing. In the world where we treat data as a bar of gold, you have to know how to work it. A few years ago, it was hard to find someone doing big data, but now I think it is a necessity. Web . A full-stack developer is a most wanted developer. In my opinion, people claiming to be full-stack developers, most of the time, prefer frontend or backend. It is good to understand both worlds. If you prefer backend, you shouldn’t be afraid to change the frontend and vice versa, but hardly I see experts in both words. Machine Learning. If you are a Software Engineer, machine learning is an entirely different career path. Machine learning models are becoming more and accessible, so you will only benefit from knowing how machine learning models are built or how to train and work with an artificial neural network. Unix. Why do I recommend Linux or Mac for a Software Engineer? Because of Unix Philosophy. For example, text Processing Toolset. You may state that a Software Engineer should write software and should not work with raw files. Far too often, I see a use-case for tools like sed, awk, or even simple grep does the job. That and many other tasks are simple in Unix. DevOps toolbox. In your company, your infrastructure for services is probably ready and configured, and there is a dedicated person to run and manage that thing. Unfortunately, problems are unavoidable. Knowledge of how and where your services are running may be crucial when there is some failure. Site Reliability Engineer mindset. By this, I understand how to release, monitor, manage an emergency, and all things that you can read in a free by Google Engineers Every software developer who has an application on production should embrace those concepts. Computer architecture. Do you know a computer or server architecture? Do you know about CPU caches, RAM, or network bandwidth? Do you know the limitations of hard disks? It is essential to understand bare metal machines and their physical limitations. It is also good to know about computer construction. Nowadays, we tend to go to the shop and buy a notebook. It might be an unusual experience to build a PC from scratch by yourself. TrendyIn this section, you have to answer what is trendy right now. Take a look and write your answers. Do not be sentimental about past technologies. It is not a confession. Core programming language: …….. Main framework: …….. Monitoring: …….. CI/CD: …….. Build tool: …….. Asynchronous and non blocking communication: …….. Version Control: …….. Some choices are clear to me and rather stable - Git as a version control system. Your primary programming language probably influences other choices. That is fine, as soon as you are aware that you are not working in obsolete and deprecated technologies. My programming language of choice is Java (but I have a remarkably pleasant experience with Kotlin), with Gradle as a built tool and git as version control, with project reactor. I know that the project reactor is ugly. Keep in mind that the topic of asynchronous and non-blocking communication is continuously changing. At the begging it was CompletableFuture, then it was RxJava. Now it is a choice between Project Reactor and Kotlin Coroutines. PeopleTechnical skills are not everything. Software Engineers work in teams, so communication skills are as relevant as the ability to code. Communication. For me, excellent communication is not about speaking or giving a great presentation. Speaking may be a monologue. Dialogue is when you listen actively to others. Never assume that you know other person intentions or goals. Paraphrase and ask for clarification. Be authentic. Do not pretend someone you are not.Language: Business and technical. Communication is tricky. Business people tend to see profits and results, unlike technical people, who tend to see problems and potential bugs. You have to learn how to communicate your ideas to different groups of people. Respect. It is a magic glue that holds teams together. We are all equal, so we should treat everyone in the same way. Our workplaces should allow expressing ourselves freely. You have to do it professionally and cut down any insult or aggression. Willing to help. Giving useful information or advice to your teammate is a great way to build a relationship. Soon you realize others became willing to help you in the moments when you need it. Give and receive feedback. Providing high-quality, fact-based, structural feedback is hard. What is harder? Receiving feedback. No one likes to be criticized, and far too often we make it personal. When we make it that way, we became defensive. Thus we do not accept the feedback and remove any chance to improve ourselves. ProductWe - software developers - do not make software just for fun. We do not use design patterns because someone at the conference said so. Our product should be the most useful for our clients, with the right features; hence we built maintainable software that is easy to extend. Focus on product, not tasks . It is easy to forget about the product when working with some issue tracker. Task after task, swiping from TODO column to DONE. Stop for the moment and look for business value gain in those tasks. If there is little to none product improvement in your tasks, there is something wrong. On the other hand, if there are only business tasks and no time for maintenance (or technical debt), there is also something not right. Propose new features. Although stakeholders or business people are good at business, they are not experts in technology. I’ve noticed that the best ideas and solutions came from technical people - developers, designers, product owners. Having a good idea is one thing, but having the courage and charisma to propose your ideas is another thing. If you have good ideas, you also have to communicate them effectively. Public relations. There is going to be a time when your system will not be working correctly or will be down. It may be due to deployment of the new version of the system, hardware or network failure, wrong configuration. No matter what was the cause, you have to clean up the mess, and you have to it professionally. This process usually has three steps: a) Fix the problem. Make the system healthy again.b) Repair potential damage.c) Introduce changes to avoid similar emergencies. What is essential during this time is communication. You have to communicate what happened, what was the impact when the solution is going to be deployed. In the end, writing a blameless postmortem is a thing that helps the whole organization to learn and improve. Predict (next) requirements. You have written and deployed your first service from scratch. Soon after that, there are new requirements to develop in that service. There are features often omitted (sometimes on purpose) in the first version of the service and always required in the next iterations. I find that the most popular cases are: a) Reporting and analytical module.b) Authorization mechanism.c) System readiness for A/B testing.d) Data search features. You have to predict or at least talk about those common features at the beginning of the project. Discussing those may help you better plan and organize the design of your system. LearningDuring my time at university (5 years at Warsaw University of Technology), the most important thing which I learned was learning how to learn. It is vital to know your possibilities in self-learning. Most of the things that I know are from self-study. It is apparent that I had and still have mentors that point me in a direction, but I’ve to learn by myself. Below are 6 things that I use to learn new things. Books. My average peace of reading is about 15 books a year. It is not much. I’m trying to read books that suit me well. I use Goodreads to find new inspiration. You can see books which I read here Blogs. There a lot of useful blogs to read online. I’ve discovered many exciting blogs from my friends, who shared with me interesting articles. I’ve also added those blogs to my RSS Reader: Feedly so that I can stay up to date.Podcasts and vlogs are modern forms of blogs. I can listen to them on the bus on the headphones. It is the most convenient form for me. Conferences (offline). I like traveling to conferences. I’ve to admit that my attitude toward the conference changed. At the beginning of my career, I was eager to listen to every conference talk. Now, most value for me is meeting with people, discussing novelties and trends. Conferences (online). Nowadays, conference talks are available online - on YouTube. Because you can speed up or pause the video, I prefer this form of watching conference talks. Workshops. I love attending workshops. During the workshop, you have a unique ability to focus on a problem, experience new tools on hand. You can discuss the unknowns with the mentor. Knowledge sharing. And by this, I do not mean to be a rock star speaker or world-famous blogger. It is about helping your colleagues every day, about small things. Whenever you are giving a piece of small advice, you often make sure that this is the right and correct, you often do some research and discover new things. Maybe someone else has a different point of view, and you can learn something new. The code review process is a great place to start. Famous polish speaker Jacek Walkiewicz said: “Kto przewiezie innego człowieka swoją łodzią na drugi brzeg, sam też tam dopływa.” My translation is: “Who will carry another man with his boat to the other side, he also arrives there.” You have to notice if you support someone else, you also support yourself. MotivationWhat motivates you? Are you desirous to wake up early and code, or maybe each day in the office is a nightmare for you? For me, if I weren’t a geek, I couldn’t be a software engineer. Look what is under the hood. No matter what project you do, sooner or later, something goes wrong, and going deep is inevitable. You may debug your framework or analyze the internals of your database. You should not be afraid to do that. Studying how your toolset works before is even better. Passion. I firmly believe that you have to love computers and software to be successful as a software developer. Only if you are devoted to something, you can be successful at it. Some people say that they have never worked a day in their life because they love their job so much. In my opinion, passion helps help you wade through the hassle, which happens from time to time. Curiosity. Steve Jobs once said: “Stay hungry, stay foolish.” I continuously try to do better. Rewrite some method, refactor some piece of code, try to redesign architecture to be more resilient. Never assume that you are an expert in something - there is always a bigger fish. Experiment, discover new things and have fun. SummaryAlthough we have smarter IDE’s, better tools to design software, more productive programming languages, core principals of software engineering didn’t change much. Our computers use Von Neumann architecture, introduced in 1945. For over 50 years, our programs are still often imperative focused on achieving specific goals.Stability is a good thing because core concepts are the same; you only need to change tools. We place great value on configuring and designing our programs to be resilient to an emergency, network failures. Smaller or bigger innovation is a natural part of our process. The only constant in life is a change. Sooner or later, you are going to unlearn what you know and learn new things. What is going to be? I can not predict the future. Photo credit","link":"/2020/04/se-roadmap/"},{"title":"NameCollision 2013","text":"Dnia 22 lutego, odbył się hackaton o nazwie NameCollision. Impreza zaczęła się punktualnie. FlashTalki dobrze nastawiły ludzi, do zrobienia czegoś fajnego. Jest trochę po 19. W tym momencie mój film się urywa, gdyż z nowo poznaną osobą przystąpiliśmy do realizacji naszego projektu. Atmosfera ludzi kodujących coś w około powodowała, że jeszcze bardziej skupiałem się na tym co chcieliśmy osiągnąć.Przegapiłem ciepły posiłek, posiliłem się tylko kilkoma kanapkami. Udało się wykonać to co z kolegą sobie założyliśmy, że zrobimy.Dochodzi północ, moje bezpieczniki wysiadły, po całym dniu wstawania o 6 rano i chodzenia spać około 11, padłem. Jedyne o czym myślałem to sen.Miłą niespodzianką na koniec były nagrody dla osób twardo kodujących :) Po powrocie do domu około 3 w nocy, mój organizm powiedział, że ty już nie musisz spać i możesz kodować dalej ;pChciałbym podziękować organizatorom i sponsorom za tak świetnie przygotowany wieczór. Było ekstra. Więcej takich wydarzeń !PS. Internet był niesamowity. 100Mbitów symetrycznego łącza, które działało bez zarzutu. Brawo dla organizatorów :) Photo credit","link":"/2013/02/name-collision/"},{"title":"The Dream Team Nightmare","text":"My previous experience with agile books was not so good. For one thing, they’re overfilled with advices and strategies, often without context. Put differently, it always required some additional effort, to imagine newly discovered strategies in my past experience. As a consequence, it may not be properly understand and implemented by my. 5 days of team liveMain character of this book is a agile coach. He is hired by a company to help with underperforming team - the Dream Team. The book is sliced into about 250 chapters. In addition, every chapter is a new chance to learn something new. I’ve marked 26 notes, related to: decision making dealing with situations under pressure meeting techniques (e.g. retrospectives) asking correct questions self-organization effective communication good practices (or habits) metering possibilities planning preserving an argument Most significantly, you can clearly see all these techniques in the same order as in Spock testing framework Given - full specification of the problem When - action taken to resolve Then - result of those actions Reading this bookYou can find it, in a book category on amazon. But it is really a book? I do not think so. It was more like game for me. Every ~10 chapters you have to made a decision. Every decision you made may lead to fail or success of your mission. At first I was confused about this approach and I came back to previous choices and where they lead me. After reading a about 50 pages I decided to draw a chapter graph (with decision), and come back to paths that I not chosen when I read the whole book. OutcomeAs a result, I’ve managed to made only good choices and lead the team to happy ending. The graph was on five A4 pages. It looks like this: In contrast to good choices, failure paths showed me where the team my end. Learning from someone else mistakes is most important lesson for me.I would like to thank Wojtek Erbetowski for recommending me this book. Photo credit: Nightmare","link":"/2015/11/the-dream-team-nightmare/"},{"title":"Tomcat cluster with mod_jk sticky session session replication","text":"Przewodnik o tym jak zrobić klaster złożony z dwóch instacji tomcata połączonego load balancerem apache mod_jk i jak uruchomić replikację sesji oraz sticky-session. System operacyjny to lubuntu 11.10. Z góry przepraszam, za dość surowe komendy. Nie jest to tutorial krok-po-korku ani książka, żeby rozlegle wszystko opisywać. Jest to tylko ściągawka na przyszłość, lub ekstrakt z tego co trzeba zrobić. Adres IP należy zmienić z 10.0.0.90 na localhost czy gdzie tam wasz serwerek się znajduje. Instalacja Zainstaluj: Instalacja1apt-get install apache2 libapache2-mod-jk2-mod-jk Utworz katalog: Folder1/tcluster/instance1 Pobierz Tomcata i rozpakuj zawartość do tego katalogu. Konfiguracja Apache mod_jk Utwórz plik /etc/apache2/workers.properties: Worker properties time12345678910111213141516171819202122232425worker.list=loadbalancer,mystatworker.worker1.type=ajp13worker.worker1.host=10.0.0.90worker.worker1.port=8881worker.worker1.lbfactor=50worker.worker1.cachesize=10worker.worker1.cache_timeout=600worker.worker1.socket_keepalive=1worker.worker1.socket_timeout=300worker.worker2.type=ajp13worker.worker2.host=10.0.0.90worker.worker2.port=8882worker.worker2.lbfactor=50worker.worker2.cachesize=10worker.worker2.cache_timeout=600worker.worker2.socket_keepalive=1worker.worker2.socket_timeout=300worker.loadbalancer.type=lbworker.loadbalancer.sticky_session=trueworker.loadbalancer.balance_workers=worker1,worker2worker.mystat.type=status Ważna jest nazwa workera ( worker1 oraz worker2 ) adres IP oraz port. Do pliku /etc/apache2/ports.conf dodaj: Listen port time1Listen 8585 Zmień zawartość pliku /etc/apache2/mods-enabled/jk.conf na: Mods configuration123456JKWorkersFile /etc/apache2/workers.propertiesJkLogFile /var/log/apache2/mod_jk.logJkLogLevel debugJkLogStampFormat &quot;[%a %b %d %H:%M:%S %Y] &quot;JkOptions +ForwardKeySize +ForwardURICompat -ForwardDirectoriesJkRequestLogFormat &quot;%w %V %T&quot; Dodaj nasłuch na porcie 8585 dla mod_jk. Zmień plik /etc/apache2/sites-enabled/000-default 1234&lt;VirtualHost *:8585&gt; JkMount /* loadbalancer JkMount /jkstatus mystat&lt;/VirtualHost&gt; Konfiguracja instancji nr 1:Zmień plik /tcluster/instance1/conf/server.xml tak aby przypominał: Konfiguracja Tomcata 112345678...&lt;Connector port=&quot;8871&quot; protocol=&quot;HTTP/1.1&quot; /&gt; ...&lt;Connector port=&quot;8881&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;....&lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot; jvmRoute=&quot;worker1&quot;&gt;....&lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot;/&gt; Connectora się odkomentowywuje, jvmRoute trzeba dopisać, pole cluster się odkomentowywuje. Ściągnij z PSI Probe i umieść go w katalogu webapps. Jest to aplikacja która może się później przydać. Dodaj użytkowników do tomcata. Zedytuj plik /tcluster/instance1/conf/tomcat-users.xml: Tomcat users12345&lt;tomcat-users&gt;... &lt;role rolename=&quot;manager&quot;/&gt; &lt;user username=&quot;admin&quot; password=&quot;jakieshaslo&quot; roles=&quot;manager&quot;/&gt;&lt;/tomcat-users&gt; Przejdź do katalogu: /tcluster/instance1/webapps.Zmodyfikuj _examples/WEB-INF/web.xml_ dodając distributable: Distributable12345&lt;tomcat-users&gt;... &lt;role rolename=&quot;manager&quot;/&gt; &lt;user username=&quot;admin&quot; password=&quot;jakieshaslo&quot; roles=&quot;manager&quot;/&gt;&lt;/tomcat-users&gt; Konfiguracja instancji nr 2: Skopiuj zawartość pliku /tcluster/instance1 do /tcluster/instance2 Zmień plik /tcluster/instance2/conf/server.xml tak aby zmienić: Konfiguracja Tomcat 21234567&lt;Server port=&quot;8006&quot; shutdown=&quot;SHUTDOWN&quot;&gt;...&lt;Connector port=&quot;8872&quot; protocol=&quot;HTTP/1.1&quot; /&gt; ...&lt;Connector port=&quot;8882&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;....&lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;localhost&quot; jvmRoute=&quot;worker2&quot;&gt; TestowanieUruchamiamy wszystko: Startup123/etc/init.d/apache start/tcluster/instance1/bin/startup.sh/tcluster/instance2/bin/startup.sh Testy przeprowadzić najlepiej za pomocą aplikacji z przykładów: W moim przypadku jest ona dostępna pod adresem: http://10.0.0.90:8871/examples/servlets/servlet/SessionExample Mamy trzy porty HTTP: 8871 - instancja nr 1 8872 - instancja nr 2 8585 - load balancer Po dodaniu jakiegoś aktrybutu sesji i zmianie portu z 8871 na 8872 powinniśmy mieć ten sam SessionID (Sticky-session) oraz te same atrybuty(Replikacja sesji). Dodatkowa analiza: Panel z informacja o mod_jk dostępny pod adresem http://10.0.0.90:8585/jkstatus Probe (narzędzie do monitorowania) dostępne na danej instancji: http://10.0.0.90:8871/probe oraz http://10.0.0.90:8872/probe Photo credit","link":"/2012/01/tomcat-cluster/"},{"title":"How to upgrade docker to 1.6.0 on OSX via homebrew","text":"So simple, but few my friends has problem with this. The key point is to perform boot2docker upgrade which upgrade ISO image. 123brew update brew upgrade boot2dockerboot2docker upgrade","link":"/2015/04/upgrade-docker-16/"},{"title":"Replace with Regex","text":"Ostatnio przechodziłem z HibernateSessionFactory konfigurowanego w kodzie na hibernate.cfg.xml.Wiąże się to z zamianą mapowań, których może być w dość dużo w projekcie: Code Configuration1configuration.addAnnotatedClass(pl.myproject.MyClass.class); Każda klasa reprezentująca encje musi zostać zamieniona na coś takiego: Code Configuration1&lt;mapping class=&quot;pl.myproject.MyClass&quot;&gt; Najprostsze rozwiązanie jakie przychodzi to użycie zamiany z użyciem wyrażenia reguralnego. W naszych IDE należy włączyć tryb zamiany z użyciem wyrażenia reguralnego. W polu “find” definiujemy: Code Configuration1configuration.addAnnotatedClass\\((.*).class\\); W polu “replace” definiujemy: Code Configuration1&lt;mapping class=&quot;$1&quot;&gt;&lt;/mapping&gt; Klikamy “Replace All” i zrobione. Nie ma tutaj nic trudnego. Wybranie pierwszego podzbioru za pomocą dwóch nawiasów i wstawienie tego za pomocą $1.Proste,a nawet banalne.Za pewne każdy edytor tekstu potrafi takie rzeczy, jednak odnoszę wrażenie, że zbyt często próbujemy robić takie rzeczy ręcznie. Photo credit","link":"/2012/12/regex-ide/"},{"title":"Used and budged Mac - 2015","text":"This post will be in Polish, because it corresponds to Polish market and prices. Używany Mac, na każdą kieszeń - 2015Dlaczego chcę o tym napisać?Dużo moich znajomych zauważyło, że zmieniam komputery Apple jak rękawiczki. Często proszą mnie o opinię jaki komputer Apple kupić, zwłaszcza gdy nie mają luźnych kilku tysięcy na nowy sprzęt. Najczęściej chcą kupić coś używanego, na próbę. Postanowiłem więc napisać krótki przewodnik po świecie używanych komputerów Apple, które można kupić w Polsce. Moja historiaNigdy nie sięgnąłbym po komputery Apple, gdybym nie potrzebował komputera, który pozwoli skupić mi się na tym co naprawdę lubię i chcę robić. Uwielbiam bawić się Linuxem. Mnogość narzędzi i możliwości tych systemów sprawiały, że mogłem godzinami ciągle coś zmieniać, poznawać wiele różnych dystrybucji. W pewnym momencie stało się dla mnie jasne, ze potrzebuję komputera, którego nie będę mógł ‘popsuć’, którego będę mógł traktować jako infrastrukturę (która jest niezawodna, niezawracająca głowy). Rozwiązaniem było tylko Apple. Natywne narzędzia *nixowe, połączone z rzeczami, które zawsze powinny działać. Swoją przygodę z Makami zacząłem w roku 2006 od komputera iBook G4 z systemem OS X Tiger. Był to świetny komputer, ale niestety maszyna się zestarzała, a nowy komputer był poza moim zasięgiem ze względu na cene. Wobec, tego na początku był biały MacBook, potem Unibody MacBook, MacBook Pro, MacMini, MacBook Air, iMac, drugi MacBook Pro, drugi MacMini. Wszystkie te komputery oprócz ostatniego jednego MacBook Pro były używane. Zdobyłem trochę doświadczenia w selekcjonowaniu ofert, ale mimo to kilka razy się sparzyłem. Gdzie szukać ofert sprzedaży komputeraPoszukiwania skupiam na trzech głównych miejscach: Allegro - Największy wybór. Forum MyApple - Oferty z zadbanym sprzętem. OLX - Zazwyczaj najtańsze oferty. Dla kogo?Komputer powinien być dla każdego. Komputer bez problemu powinien radzić sobie z mnogością otwartych stron, programem pocztowym, komunikatorem internetowym, kilkoma dodatkowymi programami. Ten wpisŻeby poprawnie zinterpretować ten artykuł wymagana jest podstawowa znajomość budowy komputera (dysk twardy, procesor) Jeżeli jesteśmy hobbystami komputerowymi, operacje wymiany niektórych podzespołów komputera (dysk twardy, pamięć ram, bateria) możemy przeprowadzić sami. Jeżeli nas to nie interesuje, zalecam oddanie sprzętu do serwisu. Koszty nie powinny być wysokie, gdyż to są operacje rutynowe Do przeprowadzenia tych czynności, musimy mieć podstawowe zdolności manualne, umiejętność czytania instrukcji iFixIt, zestaw śrubokrętów za kilkadziesiąt złotych i wiare w siebie. Przy wykonywaniu czynności serwisowych, pamiętajmy o odłączeniu zasilania, nie dotykaniu kondensatorów, gdyż mogą być ciągle naładowane, oraz o ‘rozładowaniu się’ np. poprzez dotknięcie kaloryfera. Co powinniśmy wiedzieć?Oprócz nazw produktu np. iMac lub MacBook, przyjęło się, że rozróżniamy komputery poprzez złożenie daty zaprezentowania określone za pomocą słów (Early, Mid, Late), roku oraz modelu np. MacBook Mid 2012. Każdy produkt ma oczywiście identyfikator modelu, z kolejnym numerem wersji np. MacBookPro9.2, oraz bardziej szczegółowy numer produktu. Do poprawnej identyfikacji sprzętu wystarczy oznaczenie modelu z datą. O wszystkim tych modelach można przeczytać na wikipiedii. Lektura z którą warto się zapoznać przed zakupem komputera. Jaki komputer? Zazwyczaj rozmowa zaczyna się od pytania: “Jaki komputer powinienem kupić?” Zazwyczaj odpowiadam, że do wyboru mamy Komputery stacjonarne: Mac Mini. Modele od Early 2009. Przedział cenowy od około 1000 zł, do nawet 3000 zł. iMac. Modele od Late 2009. Przedział cenowy od około 2500 zł - 6500 zł. iMac Retina. Modele 2014, 2015. Ceny zaczynają się od około 7000. Komputery przenośne: MacBook Air 11”/13” od modelu Mid 2011. Ceny w przedziale 2500-4000 zł. MacBook 13”, Core2Duo MacBook Pro 13”. Ceny w przedziale 1000-2000 zł. MacBook Pro 13”. Ceny w przedziale 2000-3500 zł. Retina MacBook Pro 13”. Ceny zaczynają się od około 3500-4000zł. MacBook 15” od modelu Early 2011. Ceny w przedziale 3000-4500zł. Retina MacBook 15”. Ceny od 5000 zł. Nie wymieniłem komputerów MacPro oraz MacBook 17”. Jeżeli wiesz, że takiego potrzebujesz, to na pewno się nim zainteresujesz. Podane ceny są cenami orientacyjnymi. Niewykluczone, że znajdą się oferty tańsze, jak i droższe, które będą zapewne stosownie uzasadnione. Wymienione wyżej ceny tracą na aktualności z każdym dniem. Za rok, czyli jesień 2016, ceny na pewno się zdezaktualizują. Uwaga odnośnie ofertZ mojej obserwacji wynika, że oferty możemy podzielić na 3 kategorie: komputery wyceniane za drogo. Można zauważyć oferty, które są aktualne przez kilka miesięcy, komputery z defektami. Oczywiście cena jest atrakcyjna, jednak może być nieadekwatna do ilości problemów jakich komputer może nam przysporzyć, komputery, które są warte zakupu. Zazwyczaj sprzedają się w ciągu kilku dni. Proces zakupu warto rozłożyć na kilka tygodni. Warto przejrzeć oferty raz na tydzień. Dopiero po 3-4 tygodniach radzę zdecydować się na zakup.Szczególną ostrożnością trzeba się wykazać przy zakupie komputera oferowanego przez komisy. Często takie komputery trafiają do nas z zagranicy, są w słabym stanie technicznym, często były eksploatowane bardzo intensywnie, nie wiadomo czy nie mają ukrytych uszkodzeń. Nie traktujmy jednak tego tak, że ktoś chce nas oszukać, a raczej postarajmy się zrozumieć jaką historię ma sprzęt i czego możemy się spodziewać. Na szczęście sprzedawcy zapewniają ‘gwarancje rozruchowe’.Obserwujemy oferty sprzedaży jakiejś serii komputera np. MacBook Pro 13”. Większość modeli oferowanych będzie starszych, tylko kilka ofert będzie dotyczyło modeli nowszych, mimo że będą w podobnych cenach. Starsze modele będą długo obecne w ofercie, dopóki sprzedawca nie zejdzie z ceny. Nowsze modele, zazwyczaj szybko się sprzedają. Serwisowanie i upgrade podzespołów Kiedyś w większości laptopów można było wymienić procesor na mocniejszy, tak jak robi to się w stacjonarnych komputerach PC. Teraz sprzedawane są komputery w których jedyne co możemy zrobić, to oczyścić wentylator z kurzu. Oczywiście konsumenci oczekują komputerów, mniejszych, lżejszych itp. To jest cena jaką trzeba zapłacić. W produktach Apple zawsze był widoczny trend, żeby użytkownik nie miał potrzeby dostawania się do środka komputera. Tylko serwisanci powinni widzieć wnętrze komputera. Oczywiście jest wiele dyskusji na ten temat. Nie zacznę kolejnej. Moim celem jest jedynie zaznaczenie niektórych ograniczeń, na które warto zwrócić uwagę przy zakupie komputera. Ilość rdzeni procesoraKomputery, które wymieniłem mają 2 lub 4 fizyczne rdzenie procesora. Jeżeli zastanawiasz się czy wykorzystasz 4 rdzeniowego procesora, możesz spokojnie kupić 2 rdzeniowy procesor. Jeżeli twoja praca wymaga 4 rdzeniowego procesora musisz zawęzić swoje poszukiwania do Mac Mini (niektóre modele), MacBook Pro 15”, iMac (niektóre modele). Pierwszym czynnikiem na jaki warto zwrócić uwagę to oznaczenie serii procesora:stronie Intela. Powie nam to bardzo dużo o procesorze i jego przeznaczeniu. Jak dowiedzieć się czegoś więcej o procesorze? Wystarczy podać oznaczenie procesora na stronie ark.intel.com. Jak porównać szybkości procesora? Zaglądamy na BenchmarkPrzydatne, jeżeli porównujemy kilka modeli komputerów. Pamięć RAMNie polecił bym nikomu zakupu komputera (czy to PC czy Apple), z ilością pamięci mniejszą niż 8GB, bez możliwości rozbudowy. Do żwawej pracy w kilku aplikacjach (lub kilku użytkownikach) potrzeba takiej ilości pamięci RAM. Zgodzę się natomiast, że da się pracować na komputerze z 4GB pamięci RAM. Należy uważać, żeby nie mieć otwartych 50 kart w przeglądarce internetowej, zamykać niepotrzebne programy. Oczywiście nie wchodzą w grę cięższe aplikacje lub wirtualizacja. 4GB jest w sam raz jeżeli raz na tydzień chcemy sprawdzić maila, a komputera używamy maksymalnie kilka godzin tygodniowo. Ponieważ widzę jak ludzie pracują na komputerach, nie poleciłbym nikomu komputera z 4GB RAM, ponieważ nie chcę słuchać narzekania, że komputer czasami przeżywa chwile słabości. Jeżeli mamy dysk SSD, 4GB RAM może nam tak bardzo nie doskwierać. W przypadku dysku talerzowego będzie to na pewno bardzo odczuwalne. W związku z tym przyjmuję zasadę, że skreślam komputery, które nie potrafią obsłużyć 8GB pamięci RAM. Dyski twardeDyski SSD, charakteryzujące się znakomitą wydajnością, co więcej stały się bardzo tanie. Jeżeli kupujemy komputer z tradycyjnym dyskiem talerzowym, zalecam każdemu wymianę na dysk SSD (oczywiście jeżeli to możliwe). 120GB dysk twardy (kosztujący 300 zł) będzie miał ogromny wpływ na szybkość pracy naszego komputera. Komputery stacjonarneDecydując się na zakup komputera stacjonarnego (iMaka lub Maka Mini) należy pamiętać o klawiaturze. Co prawda zwykła klawiatura będzie działała z Makiem, ale żeby wygodnie pracować, niezbędna jest odpowiednia klawiatura. Polecam te przewodowe. Są wygodniejsze i tańsze. Niestety jest to często dodatkowy koszt około 200 zł. Polecam zakupić nowy produkt. W większości przypadków, komputery stacjonarne Apple są w dobrym stanie technicznym, gdyż nigdy nie opuszczają biurka. Możemy być spokojni o zalania lub uszkodzenia mechaniczne. Mac MiniW przypadku Maka Mini mamy pełną swobodę jeżeli chodzi o wymianę pamięci RAM (do 16GB) oraz dysku twardego (każdy dysk twardy 2.5” SATA). Nie dotyczy to ostatniego modelu - Late 2014. Jeżeli jesteśmy bardzo ograniczeni budżetem, a z komputera będziemy korzystali jedynie do pisania w Wordzie i obsługi poczty. Możemy poszukać Maka Mini plastikowego tj. model 2009. Jednak wydałbym na taki komputer więcej niż 1000 zł i powinien być wyposażony w 8GB RAM i/lub dysk SSD. Model Mid 2010, jest fenomenem, ponieważ jest to pierwszy model Unibody (aluminiowy), a zarazem ostatni posiadający napęd optyczny. Przed zakupem komputera należy sprawdzić działanie napędu optycznego, bywały one dość awaryjne. Niestety znajdziemy tam procesor z tej samej generacji co w modelu plastikowym. Model ten trzyma jednak bardzo dobrze cenę (1000-1500zł). Płacimy tutaj za aluminiową obudowę. Przy wyborze Maka Mini, poleciłbym zakup wersji Mid 2011 lub Late 2012, czyli z procesorami i5. Ceny modeli słabo wyposażonych zaczynają się od około 1500 zł. Doposażenie tego komputera w więcej pamięci RAM i dysk SSD pozwoli nam się nim cieszyć przez kolejne kilka lat. Za kwotę do 2000 zł powinniśmy otrzymać komputer, który ma co najmniej 8GB RAM i zamontowane dwa dyski twarde (SSD i HDD) lub jeden większy SSD. Taki komputer, będzie dobrze trzymał cenę, ponieważ jest to ostatni model, który pozwala na zamontowanie dwóch 2.5” dysków twardych, oraz rozbudowę pamięci do 16GB, co jest niemożliwe w modelu Late 2014. Na szczególną uwagę zasługują modele z 4 rdzeniowymi procesorami. Oferują one bardzo wysoką wydajność, ale jeżeli pojawią się na rynku, bardzo szybko znikają i kosztują powyżej 2000 zł. Zakup Maka Mini jest opłacalny cenowo, jeżeli mamy własny monitor. W przeciwnym wypadku, możemy rozważyć zakup iMac 21.5”. iMaciMaki są niesamowite ze względu na 27” matrycę o rozdzielczości 2560 × 1440. Model Late 2009 zapoczątkował serię ‘Unibody iMac’. W cenie do 3000 zł powinniśmy kupić komputer w wersji Late 2009 lub Mid 2010 z matrycą w dobrym stanie. Oczywiście model 27”. Niestety są to dość stare i słabe dwurdzeniowe procesory. Nie możemy od takiego komputera oczekiwać zbyt wiele, ale jest to idealna maszyna do pisania. Model 2011 jest już troszeczkę droższy ponieważ posiada 4 rdzeniowy procesor. Jest to jeden z najpopularniejszych iMaków jaki możemy spotkać na polskim rynku. Ceny sięgają nawet 5000 zł, w mojej opinii to trochę za drogo. Rozbieżność cen jest duża, ponieważ różne są konfiguracje. Od jednego talerzowego dysku twardego i 4GB RAM, do dwóch dysków SSD i 32GB RAM. Niestety iMac z tego okresu produkcji posiadają jedna wadę fabryczną. Matryca ulega procesowi zakurzenia. Koszt rozebrania matrycy i wyczyszczenia to kilkaset złotych (400-600). Jeżeli właściciel wykupił rozszerzoną gwarancję, jest spora szansa, że usterka została usunięta pod koniec 2 roku gwarancji (prawdopodobnie odbyła się wymiana matrycy na nową). Stan matrycy jest to kluczowy element na który trzeba zwrócić uwagę, przy zakupie takiego iMaka. W cenie około 2500 zł powinniśmy kupić Unibody iMac 21.5” z analogicznego okresu produkcji. iMac był dystrybuowany razem z myszką i klawiaturą, więc może to być idealny pierwszy komputer Mac w dobrej cenie. W iMakach wymiana pamięci RAM jest prosta. Otwieramy klapkę z tyłu komputera i wykładamy kości. Natomiast dostanie się do dysku twardego wymaga wymontowania matrycy. Jest to możliwe do zrealizowania w domowych warunkach, ale wymaga już trochę zdolności manualnych. Oczywiście iFixIt naszym przyjacielem jest. Począwszy od Modelu Late 2012, iMac stał się smukły. W roku 2013 dostał nowe procesory. Dostępność tych komputerów na rynku wtórnym jest niewielka. Zapewne z tego powodu, gdyż są to komputery z bardzo dobrymi parametrami i pierwsi właściciele nie chcą się z nimi rozstawać. Modele slim, to wydatek zdecydowanie powyżej 4000 zł. W 2014 zaprezentowano 27” model z wyświetlaczem Retina o rozdzielczości 5120 × 2880. Pierwsze używane modele kosztują w okolicy 7000 zł. Jest to około 1000-1500 zł taniej niż nowy komputer. Komputery przenośneUszkodzeniaNależy zwrócić szczególną uwagę na stan laptopa przed zakupem. Należy dokładnie sprawdzić czy nie posiada wgnieceń na rogach. Mogą to być pozostałości po upadku. Przez wgniecenia na rogach, komputery mogą się nie domykać, przez co matryca może się wykrzywiać, mogą być problemy z otwieraniem ekranu. Zdecydowanie nie polecam zakupu takiego komputera, nawet jeżeli jest znacznie tańszy niż inne komputery z tego modelu. Jeżeli natomiast jesteśmy zdeterminowani, a uszkodzenie wydaje się powierzchowne, należy taki komputer obejrzeć osobiście czy działa sprawnie - przede wszystkim zamykanie i otwieranie. Zalecam również poproszenie właściciela o zdjęcie tylnej klapy komputera. Kiedyś rozważałem zakup takiego komputera, jednak po zdjęciu klapy ujrzałem poklejone na super-glue elementy mocowania głośnika. Zawsze zakładam, że sprzedawca jest uczciwy, a cena powinna być adekwatna do stanu produktu w jakim on jest. Jedyne czego pragnę, to bycie w pełni świadomym co kupuje i za jakie pieniądze. Należy sprawdzić czy wszystkie klawisze w laptopie stawiają jednakowy opór. W przypadku zalania (np. sokiem), niektóre guziki będą chodziły ciężej, oraz bez charakterystycznego kliknięcia. Nie każdy zwraca na to uwagę, niektórzy mogą uznać to za nieważny detal. Jednak sprzęt który był zalany, mimo wysuszenia, może po pewnym czasie odmówić współpracy. Jeżeli mamy podejrzenia, że laptop mógł być zalany (mimo, że właściciel wypiera się, że nie był), również możemy poprosić o zdjęcie klapy i o poszukanie śladów zalania. Możemy poszukać, gdzie w danym komputerze znajdują się wskaźniki zalania i je sprawdzić. Jednak nie zawsze jest to możliwe. Jeżeli mam jakieś podejrzenia, że sprzęt był zalany, wolę odpuścić taką ofertę. O zasilaczachNigdy nie kupuj laptopa, jeżeli ten posiada zamiennik oryginalnego zasilacza. Podróbki są awaryjne. Iskrzą przy podłączania do gniazda. Jeżeli kupujesz laptop z polskiej dystrybucji, w zestawie powinieneś otrzymać krótką końcówkę zasilacza jak i końcówkę zasilacza z około 1.5 metrowym kablem. Zwróć uwagę w jakim stanie jest kabel w rejonie wtyczki MagSafe oraz przy wyjściu z zasilacza. Jeżeli jest napuchnięty, lub widoczne są pęknięcia, może to oznaczać konieczność wymiany całego zasilacza, gdyż wymiana samego kabla może być nie opłacalna. O bateriachBateria w kilkuletnim laptopie, spokojnie może mieć kilkaset cykli. Jeżeli ma ponad 500, powinna nam się zapalić żółta lampka, żeby sprawdzić jaka pojemność baterii została. Baterie nie zużywają się równomiernie i ilość cykli nie powinna być głównym wyznacznikiem jej stanu. Jeżeli po kliknięciu na ikonę baterii, widzimy napis “Service battery”, może to oznaczać konieczność wymiany baterii. Jednakże, najlepiej sprawdzić pozostałą pojemność baterii w oknie dotyczącym informacji o komputerze. Czy wymiana jest prosta i możliwa do wykonania w domowym zapleczu? W MacBook Air, każdy powinien sobie z tym poradzić. Niestety w Retina MacBook Pro jest już gorzej, gdyż bateria jest przyklejona i trzeba uważać. Warto oddać sprzęt specjaliście. MacBook AirMacBook Air jest to najlepszy laptop codziennego użytku, jaki możemy kupić na rynku wtórnym. Jest to jednostka mała, z długim czasem pracy na baterii, dobrą matrycą, oraz jak na swoje wymiary, zadowalającym procesorem. Polecam model Mid 2011 i nowsze. Poprzednie generacje cechowały się dużo słabszymi procesorami oraz mniejszą rozdzielczością matrycy. Jeżeli głównie będziemy pracowali bez użycia zewnętrznego monitora, wygodniejszy jest model 13”. Jeżeli natomiast dużo podróżujemy, a pracujemy na zewnętrznym monitorze, bezkonkurencyjny jest model 11”. W tym modelu pamięć RAM jest niemożliwa do wymiany. Wśród 41 Airów jakie znalazłem w ogłoszeniach, tylko 3 posiadały 8GB pamięci RAM. Zazwyczaj były to nowe komputery, często na gwarancji, a więc i ceny oscylowały w okolicy 4000 zł. Natomiast zdarzają się przypadki starszych komputerów z 8GB pamięci RAM i na takie modele warto zaczekać. Będzie to wydatek około 3000 zł. Modele 11” będą tańsze, ze względu na mniejszą popularność. W przypadku tego modelu szczególną uwagę należy zwrócić na uszkodzenia mechaniczne oraz na stan baterii. MacBook 13”, Core2Duo MacBook Pro 13”Mając do dyspozycji kwotę około 1000-2000 zł możemy myśleć nad zakupem komputera MacBook Unibody (Late 2008) oraz MacBook Pro (Mid 2009 lub Mid 2010). Ceny różnicują się ze względu na stan oraz na ilość ulepszeń jakie właściciel dokupił do komputera. Droższe modele zapewne mają zamontowane dwa dyski, w tym jeden SSD (możliwość montażu zamiast napędu optycznego) i powinny mieć wymienioną baterię. Jeżeli jesteśmy bardzo nastawieni na dobrą cenę, możemy zainteresować się modelem Polycarbonate (potocznie określane jako White). Interesują nas wtedy modele od Early 2009. Taki komputer w dobrym stanie możemy nabyć za cenę poniżej tysiąca złotych. Pamiętajmy, że cena jest niższa, gdyż plastik to nie to samo co aluminiowa obudowa. Są to najstarsze MacBooki jakie wspiera system OS X El Capitan. Jest w związku z tym szansa, że komputery nie będą wspierane przez kolejne wersje systemu operacyjnego. Ponadto, nie możemy oczekiwać rewelacji od takiego komputera. To są prawie 6 letnie konstrukcje. Niemniej, jeżeli wybierzemy zadbany egzemplarz, a nasze potrzeby są podstawowe, może być to bardzo udany zakup. MacBook Pro 13”Model Early 2011 zapoczątkował serię MacBooków z procesorami i5. Te procesory oferują przyzwoitą wydajność, komputer posiada możliwością montażu dwóch dysków, czyni go bardzo atrakcyjnym modelem. Modele ze standardowym wyposażeniem da się kupić za około 2000 zł. Ceny zadbanych modeli, z lepszym wyposażeniem kończą się na około 3000-3500 zł. Niestety komputer ma jedną zasadniczą wadę. Rozdzielczość matrycy 1280 × 800 nie zachwyca. Ponadto sam komputer jest gruby i ciężki. Tutaj musimy sobie odpowiedzieć czy zależy nam na dwóch dyskach twardych, dużej ilości pamięci ram, czy wolimy mobilność modelu Air. W większości przypadków, prawie zawsze polecam model Air. Retina MacBook Pro 13”Model Late 2012 rozpoczął serię komputerów z wyświetlaczem Retina. Ponadto w odróżnieniu od poprzednika, komputer jest pół kilograma lżejszy, posiada większą baterię i jest smuklejszy. Niestety bateria jest trudna w wymianie, pamięć ram jest częścią płyty głównej (nie można wymienić) a dysk twardy jest na PCI (brak szerokiego rynku zamienników, tak jak w przypadku dysków 2.5”). Komputer z 8GB RAM oraz 128GB SSD da się kupić taki komputer w cenie około 3500-4000 zł. Oczywiście im lepsze wyposażenie tym cena droższa, aż dojdziemy do cen nowego komputera. MacBook Pro 15”Warto rozważyć Modele 15” ze względu na matrycę o wyższej rozdzielczości, oraz czterordzeniowy procesor. Czterordzeniowe procesory były dostępne w modelach Early 2011, Late 2011 oraz Mid 2012. Za 3000 zł, możemy kupić modele z podstawowym wyposażeniem lub delikatnie obtłuczone. Ceny modeli z ostatniego roku produkcji, oraz dobrze wyposażonych sięgają 4500 zł, jednak w cenie poniżej 4000 zł powinniśmy kupić egzemplarz, który zaspokoi najbardziej wybrednych. Ceny są atrakcyjne, ponieważ większość osób poszukuje modelu 13”. Na szczególną uwagę zasługują modele z matrycą matową o rozdzielczości 1680 × 1050. Jest to coś na co warto zwrócić uwagę przy zakupie. Jest to model komputera, który rekomenduje każdemu do pracy na co dzień. Ta seria komputerów jest łatwa w naprawie i wymianie komponentów. Bez problemu możemy włożyć do komputera dwa dyski twarde, 16GB RAM oraz wymienić baterię. Retina MacBook Pro 15”Jeżeli decydujemy się na zakup takiego MacBooka, musimy być przygotowani na wydatek co najmniej 5000 zł. Tych komputerów jest mało na rynku, ponieważ pierwsi właściciele ciągle są zadowoleni z tych komputerów i nie chcą ich sprzedawać. Tak jak w przypadku modelu 13” z wyświetlaczem retina, ten komputer nie jest prosty w serwisowaniu. Jeżeli chcemy kupić komputer na lata, zadbajmy o to, żeby posiadał 16GB pamięci RAM i większy dysk twardy. PrzyszłośćNikt nie wie jaką ścieżkę rozwoju wybierze Apple. Czy jakość oprogramowania, systemu OS X będzie rosła czy malała? Czy sprzęt będzie wykonywany z największą starannością, z odpowiednich podzespołów? Czy inżynierowie i projektanci zaprezentują produkty godne uwagi? Tego nikt nie wie.","link":"/2015/11/used-and-budged-mac-2015/"},{"title":"Zen and the Art of Motorcycle Maintenance by Robert M. Pirsig","text":"This is not a book about motorcycle maintenance. This is not only a book about the zen. This is not only a novel. This is mostly a book about philosophy. But philosophy is served in nice form. This book took me to journey though a USA. I was feeling that I was an passenger of this journey. I was feeling that I was traveling with author that talks to me about philosophy. During this journey, the idea of quality and value was assembled and dissembled many times, like motorcycle parts. It was mostly presented in straightforward form and readable manner. It has a good points to think about it. But, some parts were misleading for me. I read this book because I need a change from normal technical book. My score for that book is 4 of 5 points. Photo credit","link":"/2014/06/zen-motorcycle/"},{"title":"Three levels of TDD","text":"IntroductionI’ve been using TDD technique for a few years. Most of the time with satisfactory a result. But it wasn’t an easy journey; it was a trip full of ups and downs. During this period my thinking about TDD has changed dramatically, or maybe I have changed my perception of testing and software development during this time? Indeed, yes I have. Lasse Koskela in his book called “Test Driven: TDD and Acceptance TDD for Java Developers.” wrote that “TDD is a technique that evolves together with the practitioner.” In this blog post, I would like to describe my own evolution in this matter. Level 1 - FundamentalsYou begin your journey with TDD. When you are new into something, you want to follow the rules strictly. One is TDD circle, which is “RED, GREEN, REFACTOR”. You have also heard about three laws of TDD defined by Uncle Bob: You are not allowed to write any production code unless it is to make a failing unit test pass. You are not allowed to write any more of a unit test than is sufficient to fail, and compilation failures are failures. You are not allowed to write any more production code than is sufficient to pass the one failing unit test. You are very confused about TDD because all examples that you can find relate to some mathematical/algorithmic problems. But in your daily job, you are obligated to write features, talk to DB and the other systems. You probably are struggling with complex dependencies, maybe you have to use mocks. But finally, after some practice you start to see the benefits, which are: You’ve noticed short feedback loop. Immediately, when you complete your implementation, you can launch the test to verify the correctness of your code. Test code coverage gets higher. No matter how you measure it, it will be higher. Regression is not a problem. Because when you break previous functionality during refactoring, you will instantly know that. Level 2 - RequirementsTask listsTask lists work perfectly for me. When I implement a business requirement, each small step or each corner case is represented by one task in my task list. Then for each task I write one test, often I use parametrized tests to extend tests quickly. Finally, after a few TDD circles, my task is finally completed, and I can move on. But sometimes during my work new system requirements appear. Often because the domain is so complicated that it’s hard to predict all the functionality up front. There is a big temptation to do it now, during the work on the current task, but it is dangerous. By doing it, you can lose your focus on your current goal. I’ve practiced the habit which consists of adding this new requirement as a new task to my task list and complete it after the current one. Then you gain some time to think about this need, to decide if it is an essential functionality to do. BDDAt some day, you will discover Behaviour Driven Development. For example, look at this specification: Scenario12345Scenario: Customer has a broker policy so DOB is requested Given I have a &quot;Broker&quot; policy When I submit my policy number Then I should be asked for my date of birth It is a very well written test scenario. Moreover, it is an executable scenario. This text can be executed with the tool called Cucumber. You don’t have to use it. You can use standard test framework and write your test using fluent test libraries or you can build your fluent API for tests if needed. Start writing tests that will not only check your code but also be valuable documentation for your system. Level 3 - UnderstandingShow me your tests and I will tell you everything about your code. TDD sometimes can also mean “Test Driven Design”. When you start thinking about it, your main reason for writing the tests is to refactor and re-engineer your codebase freely. For me, it is the highest value which you can get from TDD. How to achieve it? Try not to “cement” your code. Try to test interfaces or facades but not bolts and nuts of the implementation. How to check if your tests are correct? Remove production code and try to rebuild it in a different way basing only on tests. SummaryIn this article, I presented fundamental rules of TDD. The topic of requirements were also discussed. In the end, I told you about Test Driven Design which for me is a valuable part of this technique. I hope that your understanding of TDD will improve and you will start writing better tests and better systems. I gave a speech about TDD. Slides available at tdd.lewandowski.io Photo credits: Banner, Thumbnail","link":"/2017/02/thre-levels-of-tdd-1/"},{"title":"Software Developer on leadership conference? StretchCon Summary","text":"Motivation to this postSoftware developer skill set should not be limited to hard programming skills. Also, important for of our work is communication, problem understanding, self-sufficiency and other soft skills. It this blog post, I would like to show the positive aspects for software developer who participated in agile like conference. You will also find here a lot of information about Stretch Con, on which my experience is based on. As a conclusion, I’ll present what outcome Stretch conference had on me. Why I wanted to go?There are many Agile/Lean/Leadership conferences, Thus, you do not have to choose Stretch. Look around for upcoming events, meetups or trainings. There is always something going on. But in this post I’ll only focus on Stretch. On my regular basis I am software developer and at least half time of my job I spend on programming. My contribution in a company is not strictly related to any management role. I wanted to go to Stretch Con, because I’ve belived that: Everyone is a leader of himself/herself. You have to manage your time efficiently. I can learn technical things by myself (by studying them). I did not know how to develop my soft skills – or at least I did not know how to start. Understanding processes, dependencies and co-workers’ and clients’ motivations are crucial and they improve the quality of produced software. You can not connect dots looking forward. Stretch Con 15Stretch was different, unlike any other conference I have attended, mainly because of the topic but also because of the fact that it forced me to think and interact. Open spacesOpen spaces were great. Topics were shaped dynamically (voted via sli.do). It was a place where you could directly see, that other people, from different companies (different countries) have the same problems! Regular form of open spaceThose open spaces had a form of brainstorming ideas, where everyone throws an possible solution to the problem. It gave us the possibility to share and discuss ideas. Joseph discussion panelDuring the open space time, something unexpected happened. Discussion panel with Joseph Pelrine emerged. It started naturally, and eventually a lot of people accumulated around him. Gathered people asked Joseph questions, a he responded with deep explanation. Discussion was about: transparency, environment, estimation, product owner, estimation, ErlangC model. And many more topics, but I was not able note everything. For such moments, it was worth going there. Conference talksIn my opinion, on average every second talk was worth watching. I think it is a good score for single track conference. Listening to ‘leaders’, was priceless. Wide variety of subjects, helped me realize that this topic is huge. Best talksAs usual, I would like to recommend 3 presentations which are worth seeing, but there are many more that migh interest you. Visit Ustream channel to watch them. James Clear: The Surprising Power of Small HabitsAfter a great introduction, James presented detailed knowledge about the habits. He showed us techniques for shaping habits. Explained habit triggers. Finally, he also presented tricks how to sustain our habits.You can read more about habits at James Clear Page. Conference video available here. Tim Steigert: Don’t blame the goats. Get a GoatherdIt was a presentation, that forced reflection about me. It helped me tu understand who is a leader, what is the team or company and how all of it this fits into our world. Most importantly, how to ‘get’ a goatherd. Conference video available here. Joseph Pelrine: Coaching “self-organizing” teamsJoseph started his lecture with explanation of Complex systems. Then, he started discussing social self organization. Among many concepts that he presented, one particularly stuck in my mind. You have to setup for good thing to hapen naturally. Then you have to monitor them, and decide what to do more and what to stop. If you want to know how to setup things, you have to watch video. Conference video available here. Conference itselfI’ll remember this event as something positive. Here is my summary. Pros: Scene decoration was consistent with name of the conference. You may think it is not important, but it really helped me a lot, to put my brain into good mood. Content of the gift bag, including book “This is Lean“. For the first time I’ve received the book, instead of a useless gadget in gift bag. Great idea! Great venue localization. Venue itself was impressive, too. Selected conference speakers including book authors, people who change things (e.g. John Bunch - Holacracy guru at Zappos). I’ve had a feeling that Conference program committee, made many hard decisions. Cons: Everyone were talking in Hungarian. It was so hard to start a discussion during breaks. OutcomeI’ve made 464 lines of notes, from the whole conference. There were also official notes, in case I missed something. Great concept and great drawing. I was there with Wojtek. After the conference we have spend 3 hours talking and discussing Stretch content. We’ve managed only to discuss only about few talks - there were a lot of material presented there. On my way home, I’ve written down few action points, reflections about myself, that I will try to develop in the upcoming weeks. Consciously shape your habits. Turn the camera to yourself, see your actions and behaviors. Stretch your horizon, to look for new opportunities and possibilities. It will help you with problem solving. Do I really watch carefully? Try not only to hear, but carefully listen to your peers. Find better ways to communicate. Discover Holocracy and decentralized way of running organizations. Engagement, purpose, trust are more important than you think. People mindset exists. Research more about Complex systems. In conclusion, I highly recommend attending this kind of event from time to time to every software developer. Surely, you will come out as a different person.","link":"/2015/12/stretchcon15/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"33rd Degree","slug":"33rd-Degree","link":"/tags/33rd-Degree/"},{"name":"Devoxx","slug":"Devoxx","link":"/tags/Devoxx/"},{"name":"Management","slug":"Management","link":"/tags/Management/"},{"name":"Microservices","slug":"Microservices","link":"/tags/Microservices/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"Scala","slug":"Scala","link":"/tags/Scala/"},{"name":"Agile","slug":"Agile","link":"/tags/Agile/"},{"name":"Book","slug":"Book","link":"/tags/Book/"},{"name":"OS X","slug":"OS-X","link":"/tags/OS-X/"},{"name":"Clojure","slug":"Clojure","link":"/tags/Clojure/"},{"name":"Time","slug":"Time","link":"/tags/Time/"},{"name":"Concurrency","slug":"Concurrency","link":"/tags/Concurrency/"},{"name":"STM","slug":"STM","link":"/tags/STM/"},{"name":"Devoxx4Kids","slug":"Devoxx4Kids","link":"/tags/Devoxx4Kids/"},{"name":"Bash","slug":"Bash","link":"/tags/Bash/"},{"name":"Fish","slug":"Fish","link":"/tags/Fish/"},{"name":"Shell","slug":"Shell","link":"/tags/Shell/"},{"name":"Environment","slug":"Environment","link":"/tags/Environment/"},{"name":"Variables","slug":"Variables","link":"/tags/Variables/"},{"name":"CraftConf","slug":"CraftConf","link":"/tags/CraftConf/"},{"name":"Software Craftsmanship","slug":"Software-Craftsmanship","link":"/tags/Software-Craftsmanship/"},{"name":"Groovy","slug":"Groovy","link":"/tags/Groovy/"},{"name":"Functional","slug":"Functional","link":"/tags/Functional/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Maven","slug":"Maven","link":"/tags/Maven/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"Jackson","slug":"Jackson","link":"/tags/Jackson/"},{"name":"Quality","slug":"Quality","link":"/tags/Quality/"},{"name":"Jenkins","slug":"Jenkins","link":"/tags/Jenkins/"},{"name":"BitBucket","slug":"BitBucket","link":"/tags/BitBucket/"},{"name":"MCE","slug":"MCE","link":"/tags/MCE/"},{"name":"Hackaton","slug":"Hackaton","link":"/tags/Hackaton/"},{"name":"Impact Mapping","slug":"Impact-Mapping","link":"/tags/Impact-Mapping/"},{"name":"Sed","slug":"Sed","link":"/tags/Sed/"},{"name":"Xpath","slug":"Xpath","link":"/tags/Xpath/"},{"name":"Leadership","slug":"Leadership","link":"/tags/Leadership/"},{"name":"Tomcat","slug":"Tomcat","link":"/tags/Tomcat/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Hibernate","slug":"Hibernate","link":"/tags/Hibernate/"},{"name":"Regex","slug":"Regex","link":"/tags/Regex/"},{"name":"Mac","slug":"Mac","link":"/tags/Mac/"},{"name":"Zen","slug":"Zen","link":"/tags/Zen/"},{"name":"Motorcycle","slug":"Motorcycle","link":"/tags/Motorcycle/"}],"categories":[{"name":"Software Development","slug":"Software-Development","link":"/categories/Software-Development/"},{"name":"Event","slug":"Event","link":"/categories/Event/"},{"name":"Book","slug":"Book","link":"/categories/Book/"},{"name":"Technology","slug":"Technology","link":"/categories/Technology/"}],"pages":[{"title":"You have found it!","text":"404Congratulations. You have found 404 cat: I am sorry, but can you try again: using search, visit archives to browse archives, visit categories or tags to look for a post by category or by tag. My previous version of blog is deprecated. Photo credit","link":"/404.html"},{"title":"About Me","text":"My name is Michał Lewandowski. I am a software developer, a tech event organizer, a blogger and a speaker. I am also particularly interested in how people and teams work together. My hometown is Warsaw, the capital city of Poland. Software DevelopmentQuality, clean code and maintainable software are of primary importance in my work. Reading a well-crafted code makes me happy and satisfied. I’ve done various projects. I’ve done projects since the very beginning (since the first line of the code). I’ve maintained legacy code as well as code written by myself. This was amazing experience. I believe that each and every project can be done well. People and teamsI am convinced that the team is a key to a successful project. I’ve decided to spend some time on studying how does the team work and how to communicate effectively within it. My goal is to promote good values in every team. I always keep in mind, that a single expert can go fast with completing the functionality or the project, but if we want to go further, we have to form a team. Tech EventsI dovoted several months to prepare for such conferences like Warsjawa 2013 Warsjawa 2014 2014 and Codepot 2015. Besides, I also participated in WJUG organization and some smaller events like Hackwaw Disrupt, Devoxx4Kids or TestKata. Organizing events is an invaluable experience since it provides the opportunity to deal with multiple different tasks at once or negotiating on something, often for the first time. BloggerI perceive blogging as a great tool for sharing my professional experience. It requires revision as well as organization of my knowledge. When I compose a blog post and share it with the world, I’ve a feeling that I do something important that can speedup somebody’s work. SpeakerBeing a speaker is definitely an exciting thing. Preparation of a good speech takes many hours or even days. It is a final test for me when I can honestly say that I know the topic thoroughly.","link":"/about/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"},{"title":"Public activity","text":"Being a speaker is definitely an exciting thing. Preparation of a good speech takes many hours or even days. It is a final test for me when I can honestly say that I know the topic thoroughly. Conway’s Law vs MicroservicesConway’s Law impact on Microservices Article in Programistamag 8/2018 24/7How to stay productive, creative and effective.You can find up-to date slides here. 2017-06-30 at Confitura Choosing your technology stackHow we choose our technology stack? Article in Programistamag 5/2018 Software developer and dadHow to balance being software developer work and dad? Article in Programistamag 3/2018 Becoming software developerHow to become software developer? Article in Praca.pl magaizne TDDTalk about TDD.You can find up-to date slides here. 2017-09-26 discussion at Devpanel 2017-07-01 at Confitura 2017-05-16 at WJUG 2017-01-12 at Growbots Giving feedbackTalk &amp; workshop for technical people about giving a feedback.You can find up-to date slides here. 2017-09-01 at Allegro internal workshop How to become a software developer?Talk about how to become a software developer.You can find up-to date slides here. 2017-03-30 at targi.praca.pl RetrospectivesIntroductory talk about retrospectives.You can find up-to date slides here. Archive slides version available on github. 2017-02-24 at Boiling Frogs 2016-05-17 at JInkubator 2016-05-09 at Zwinna Łódż 2016-04-23 at DevCrow 2016-03-05 at Chamber conf 2016-03-04 at Touk StretchConfObservations and conclusions from Stretch Conference. Talk prepared with Wojtek Erbetowski. You can find slides here. 2016-01-11 at AgileWarsaw Domain Driven DesignDiscussion and presentation the basic concepts of Domain Driven Design. 2014-12-23 at Touk Warsjawa - Case StudyCase Study about making registration system for workshop conference - Warsjawa. Talk prepared with Tomek Netczuk and Tomek Pęksa. Event site and slides. 2014-10-28 http://warszawa.jug.pl/#/meeting/145 GitStep-by-step interactive talk about Git. You can find recording on Youtube. 2013-11-26 at JInkubator 2013-11-15 at Touk Fest AssertFlash-talk presentation about Fest Assert - Java testing library. You can find slides here. 2013-04-09 at WJUG Enterprise Integration PatternsTalk about Enterprise Integration Patters and Apache Camel as way to implement it. You can find slides here. 2013-08-02 at Touk","link":"/talks/index.html"},{"title":"Categories","text":"","link":"/categories/index.html"}]}